{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-23 20:25:24 INFO: Loading these models for language: en (English):\n",
      "=======================================\n",
      "| Processor | Package                 |\n",
      "---------------------------------------\n",
      "| tokenize  | ./model/en...ize/gum.pt |\n",
      "| pos       | ./model/en/pos/gum.pt   |\n",
      "| lemma     | ./model/en/lemma/gum.pt |\n",
      "| depparse  | ./model/en...rse/gum.pt |\n",
      "=======================================\n",
      "\n",
      "2021-06-23 20:25:24 INFO: Use device: cpu\n",
      "2021-06-23 20:25:24 INFO: Loading: tokenize\n",
      "2021-06-23 20:25:24 INFO: Loading: pos\n",
      "2021-06-23 20:25:25 INFO: Loading: lemma\n",
      "2021-06-23 20:25:25 INFO: Loading: depparse\n",
      "2021-06-23 20:25:26 INFO: Done loading processors!\n",
      "2021-06-23 20:25:26 INFO: Loading these models for language: en (English):\n",
      "=======================================\n",
      "| Processor | Package                 |\n",
      "---------------------------------------\n",
      "| tokenize  | ./model/en...ize/gum.pt |\n",
      "=======================================\n",
      "\n",
      "2021-06-23 20:25:26 INFO: Use device: cpu\n",
      "2021-06-23 20:25:26 INFO: Loading: tokenize\n",
      "2021-06-23 20:25:26 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "depparse_gum_config = {\n",
    "    'lang': \"en\",\n",
    "    'processors': \"tokenize,pos,lemma,depparse\",\n",
    "    'tokenize_model_path': './model/en/tokenize/gum.pt',\n",
    "    'pos_model_path': './model/en/pos/gum.pt',\n",
    "    'depparse_model_path': './model/en/depparse/gum.pt',\n",
    "    'lemma_model_path': './model/en/lemma/gum.pt',\n",
    "    'tokenize_no_ssplit': True,\n",
    "    'use_gpu': True,\n",
    "    'pos_batch_size': 2000\n",
    "}\n",
    "\n",
    "token_config = {\n",
    "    'lang': \"en\",\n",
    "    'processors': \"tokenize\",\n",
    "    'tokenize_model_path': './model/en/tokenize/gum.pt',\n",
    "    'tokenize_no_ssplit': True,\n",
    "    'use_gpu': False,\n",
    "    'pos_batch_size': 3000\n",
    "}\n",
    "\n",
    "gum_depparse = stanza.Pipeline(**depparse_gum_config)\n",
    "tokenizer = stanza.Pipeline(**token_config)\n",
    "from nltk.tree import Tree\n",
    "import os\n",
    "from nltk.draw import TreeWidget\n",
    "from nltk.draw.util import CanvasFrame\n",
    "from IPython.display import Image, display\n",
    "import json\n",
    "import _pickle as pickle\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dependency_parse(sentence, parser=\"gum\"):\n",
    "    return stanza_parse(sentence, parser=parser)\n",
    "\n",
    "\n",
    "def stanza_parse(sentence, parser=\"gum\"):\n",
    "    postags = {}\n",
    "    words = {}\n",
    "    parse_tree = []\n",
    "    head_log = {}\n",
    "    depdent_log = {}\n",
    "\n",
    "    parsed = gum_depparse(sentence + \"\\n\")\n",
    "    \"\"\"if parser == \"ewt\":\n",
    "        parsed = ewt_depparse(sentence)\"\"\"\n",
    "\n",
    "    for sent in parsed.sentences:\n",
    "        for word in sent.words:\n",
    "            tree_node = post_process(sent, word, postags, words)\n",
    "\n",
    "            if len(tree_node) == 0:\n",
    "                continue\n",
    "\n",
    "            if tree_node[2] in head_log:\n",
    "                head_log[tree_node[2]].append(tree_node[0])\n",
    "            else:\n",
    "                head_log[tree_node[2]] = [tree_node[0]]\n",
    "\n",
    "            if tree_node[1] in depdent_log:\n",
    "                depdent_log[tree_node[1]].append(tree_node[0])\n",
    "            else:\n",
    "                depdent_log[tree_node[1]] = [tree_node[0]]\n",
    "\n",
    "            parse_tree.append(tree_node)\n",
    "\n",
    "        enhance_parse(parse_tree, head_log, depdent_log, words)\n",
    "    return parse_tree, postags, words\n",
    "\n",
    "\n",
    "def enhance_parse(tree, heads, deps, words):\n",
    "    for node in tree:\n",
    "        if node[0] == \"conj\":\n",
    "            if \"nsubj\" in heads[node[1]] and \"nsubj\" in heads[node[2]]:\n",
    "                node[0] = \"conj-sent\"\n",
    "            elif words[node[1]][1] == \"JJ\" and words[node[2]][1] == \"JJ\":\n",
    "                node[0] = \"conj-adj\"\n",
    "            elif \"NN\" in words[node[1]][1] and \"NN\" in words[node[2]][1]:\n",
    "                node[0] = \"conj-n\"\n",
    "                vp_rel = set([\"amod\", \"compound\", \"compound\",  \"compound:prt\", \"det\",\n",
    "                              \"nummod\", \"appos\", \"advmod\", \"nmod\", \"nmod:poss\"])\n",
    "                vp_left = set(heads[node[1]]) & vp_rel\n",
    "                vp_right = set(heads[node[2]]) & vp_rel\n",
    "                if len(vp_left) and len(vp_right):\n",
    "                    node[0] = \"conj-np\"\n",
    "            elif \"VB\" in words[node[1]][1] and \"VB\" in words[node[2]][1]:\n",
    "                node[0] = \"conj-vb\"\n",
    "                vp_rel = set([\"obj\", \"xcomp\", \"obl\"])\n",
    "                vp_left = set(heads[node[1]]) & vp_rel\n",
    "                vp_right = set(heads[node[2]]) & vp_rel\n",
    "\n",
    "                if len(vp_left):\n",
    "                    if len(vp_right):\n",
    "                        node[0] = \"conj-vp\"\n",
    "                    # else:\n",
    "\n",
    "        if node[0] == \"advcl\":\n",
    "            if words[1][0] == \"if\":\n",
    "                node[0] = \"advcl-sent\"\n",
    "        if node[0] == \"advmod\":\n",
    "            if words[node[1]][0] == \"not\" and node[1] == 1:\n",
    "                node[0] = \"advmod-sent\"\n",
    "        if node[0] == \"case\" and node[1] - node[2] > 0:\n",
    "            node[0] = \"case-after\"\n",
    "        if words[node[1]][0] in [\"at-most\", \"at-least\", \"more-than\", \"less-than\"]:\n",
    "            node[0] = \"det\"\n",
    "\n",
    "\n",
    "def post_process(sent, word, postag, words):\n",
    "    word_id = int(word.id)\n",
    "    if word_id not in words:\n",
    "        postag[word.text] = (word_id, word.xpos)\n",
    "        words[word_id] = (word.text, word.xpos)\n",
    "    if word.deprel != \"punct\":\n",
    "        tree_node = [word.deprel, word_id,\n",
    "                     word.head if word.head > 0 else \"root\"]\n",
    "        return tree_node\n",
    "    return []\n",
    "\n",
    "\n",
    "def printTree(tree, tag, word):\n",
    "    if tree[0] != \"root\":\n",
    "        print(\n",
    "            f\"word: {word[tree[1]][0]}\\thead: {word[tree[2]][0]}\\tdeprel: {tree[0]}\", sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pqdict import pqdict\n",
    "\n",
    "negate_mark = {\n",
    "    \"+\": \"-\",\n",
    "    \"-\": \"+\",\n",
    "    \"=\": \"=\"\n",
    "}\n",
    "\n",
    "class BinaryDependencyTree:\n",
    "    def __init__(self, val, left, right, key, counter, id=None, pos=None):\n",
    "        self.val = val\n",
    "        self.parent = None\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.mark = \"0\"\n",
    "        self.id = id\n",
    "        self.pos = pos\n",
    "        self.key = key\n",
    "        self.is_root = False\n",
    "        self.is_tree = True\n",
    "        self.length = 0\n",
    "        self.leaves = pqdict({})\n",
    "        self.counter = counter\n",
    "        self.replaced = {}\n",
    "\n",
    "    def sorted_leaves(self):\n",
    "        self.traverse(self)\n",
    "        return self.leaves\n",
    "\n",
    "    def traverse(self, tree, multi_word=False):\n",
    "        if not tree.is_tree:\n",
    "            replacement = False\n",
    "            if str((tree.val, tree.id)) in self.replaced:\n",
    "                tree.val = self.replaced[str((tree.val, tree.id))]\n",
    "                replacement = True\n",
    "            if \"-\" in tree.val and replacement and multi_word:\n",
    "                words = tree.val.split('-')\n",
    "                words.reverse()\n",
    "                for i in range(len(words)):\n",
    "                    word_id = tree.id - i * 0.1\n",
    "                    key = (words[i], tree.pos, tree.mark, word_id)\n",
    "                    if words[i].lower() == \"not\" and len(words) == 2:\n",
    "                        key = (words[i], tree.pos,\n",
    "                               negate_mark[tree.mark], word_id)\n",
    "                    self.leaves[key] = (word_id)\n",
    "            else:\n",
    "                item = (tree.id)\n",
    "                key = (tree.val, tree.pos, tree.mark, tree.id)\n",
    "                self.leaves[key] = item\n",
    "        else:\n",
    "            self.traverse(tree.left)\n",
    "            self.traverse(tree.right)\n",
    "\n",
    "    def copy(self):\n",
    "        left = None\n",
    "        if self.left is not None:\n",
    "            left = self.left.copy()\n",
    "        right = None\n",
    "        if self.right is not None:\n",
    "            right = self.right.copy()\n",
    "        new_tree = BinaryDependencyTree(\n",
    "            self.val, left, right, self.key, self.counter, self.id, self.pos)\n",
    "        new_tree.mark = self.mark\n",
    "        new_tree.parent = self.parent\n",
    "        new_tree.is_tree = self.is_tree\n",
    "        new_tree.is_root = self.is_root\n",
    "        new_tree.leaves = pqdict({})\n",
    "        return new_tree\n",
    "\n",
    "    def set_length(self, lth):\n",
    "        self.length = lth\n",
    "\n",
    "    def set_root(self):\n",
    "        self.is_root = True\n",
    "\n",
    "    def set_not_tree(self):\n",
    "        self.is_tree = False\n",
    "\n",
    "\n",
    "hierarchy = {\n",
    "    \"conj-sent\": 0,\n",
    "    \"advcl-sent\": 1,\n",
    "    \"advmod-sent\": 2,\n",
    "    \"case\": 10,\n",
    "    \"case-after\": 75,\n",
    "    \"mark\": 10,\n",
    "    \"expl\": 10,\n",
    "    \"discourse\": 10,\n",
    "    \"nsubj\": 20,\n",
    "    \"csubj\": 20,\n",
    "    \"nsubj:pass\": 20,\n",
    "    \"conj-vp\": 25,\n",
    "    \"ccomp\": 30,\n",
    "    \"advcl\": 30,\n",
    "    \"advmod\": 30,\n",
    "    \"nmod\": 30,\n",
    "    \"nmod:tmod\": 30,\n",
    "    \"nmod:npmod\": 30,\n",
    "    \"nmod:poss\": 30,\n",
    "    \"xcomp\": 40,\n",
    "    \"aux\": 40,\n",
    "    \"aux:pass\": 40,\n",
    "    \"obj\": 60,\n",
    "    \"iobj\": 60,\n",
    "    \"obl\": 50,\n",
    "    \"obl:tmod\": 50,\n",
    "    \"obl:npmod\": 50,\n",
    "    \"cop\": 50,\n",
    "    \"acl\": 60,\n",
    "    \"acl:relcl\": 60,\n",
    "    \"appos\": 60,\n",
    "    \"conj\": 60,\n",
    "    \"conj-np\": 60,\n",
    "    \"conj-adj\": 60,\n",
    "    \"det\": 55,\n",
    "    \"det:predet\": 55,\n",
    "    \"cc\": 70,\n",
    "    \"cc:preconj\": 70,\n",
    "    \"nummod\": 75,\n",
    "    \"fixed\": 80,\n",
    "    \"compound\": 80,\n",
    "    \"compound:prt\": 80,\n",
    "    \"fixed\": 80,\n",
    "    \"amod\": 75,\n",
    "    \"conj-n\": 90,\n",
    "    \"conj-vb\": 90,\n",
    "    \"dep\": 100,\n",
    "    \"flat\": 100,\n",
    "    \"goeswith\": 100,\n",
    "    \"parataxis\": 100\n",
    "}\n",
    "\n",
    "\n",
    "class UnifiedCounter:\n",
    "    def __init__(self, initial_val=0):\n",
    "        self.addi_negates = initial_val\n",
    "        self.unifies = initial_val\n",
    "        self.nsubjLeft = False\n",
    "        self.expl = False\n",
    "        self.willing_verb = False\n",
    "\n",
    "    def add_negates(self):\n",
    "        self.addi_negates += 1\n",
    "\n",
    "    def add_unifies(self):\n",
    "        self.unifies += 1\n",
    "\n",
    "    def is_unified_clause_subj(self):\n",
    "        return self.unifies % 2 == 1 and self.nsubjLeft\n",
    "\n",
    "\n",
    "class Binarizer:\n",
    "    def __init__(self, parse_table=None, postag=None, words=None):\n",
    "        self.postag = postag\n",
    "        self.parse_table = parse_table\n",
    "        self.words = words\n",
    "        self.id = 0\n",
    "        self.counter = UnifiedCounter(0)\n",
    "        self.replaced = {}\n",
    "\n",
    "    def process_not(self, children):\n",
    "        if len(children) > 1:\n",
    "            if children[0][0] == \"advmod\":\n",
    "                if self.words[children[1][1]][0] == \"not\":\n",
    "                    return [children[1]]\n",
    "        return children\n",
    "\n",
    "    def compose(self, head):\n",
    "        children = list(filter(lambda x: x[2] == head, self.parse_table))\n",
    "        children.sort(key=(lambda x: hierarchy[x[0]]))\n",
    "        children = self.process_not(children)\n",
    "\n",
    "        if len(children) == 0:\n",
    "            word = self.words[head][0]\n",
    "            tag = self.words[head][1]\n",
    "            binary_tree = BinaryDependencyTree(\n",
    "                word, None, None, self.id, self.counter, head, tag)\n",
    "            binary_tree.replaced = self.replaced\n",
    "            self.id += 1\n",
    "            binary_tree.set_not_tree()\n",
    "            return binary_tree, [binary_tree.key]\n",
    "        else:\n",
    "            top_dep = children[0]\n",
    "        self.parse_table.remove(top_dep)\n",
    "\n",
    "        left, left_rel = self.compose(top_dep[1])\n",
    "        right, right_rel = self.compose(top_dep[2])\n",
    "        if \"conj\" in top_dep[0]:\n",
    "            dep_rel = \"conj\"\n",
    "        elif \"case\" in top_dep[0]:\n",
    "            dep_rel = \"case\"\n",
    "        elif \"advcl\" in top_dep[0]:\n",
    "            dep_rel = \"advcl\"\n",
    "        elif \"advmod\" in top_dep[0]:\n",
    "            dep_rel = \"advmod\"\n",
    "        else:\n",
    "            dep_rel = top_dep[0]\n",
    "\n",
    "        binary_tree = BinaryDependencyTree(\n",
    "            dep_rel, left, right, self.id, self.counter)\n",
    "        binary_tree.left.parent = binary_tree\n",
    "        binary_tree.right.parent = binary_tree\n",
    "        binary_tree.replaced = self.replaced\n",
    "\n",
    "        left_rel.append(binary_tree.key)\n",
    "        self.id += 1\n",
    "        return binary_tree, left_rel + right_rel\n",
    "\n",
    "    def binarization(self):\n",
    "        self.id = 0\n",
    "        self.relation = []\n",
    "        root = list(filter(lambda x: x[0] == \"root\", self.parse_table))[0][1]\n",
    "        self.counter = UnifiedCounter(0)\n",
    "        binary_tree, relation = self.compose(root)\n",
    "        binary_tree.set_root()\n",
    "        binary_tree.length = len(self.words)\n",
    "        return binary_tree, relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pattern.en import conjugate\n",
    "from nltk.tree import Tree\n",
    "from nltk.draw import TreeWidget\n",
    "from nltk.draw.util import CanvasFrame\n",
    "from IPython.display import Image, display\n",
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "import _pickle as pickle\n",
    "\n",
    "arrows = {\n",
    "    \"+\": \"\\u2191\",\n",
    "    \"-\": \"\\u2193\",\n",
    "    \"=\": \"=\",\n",
    "    \"0\": \"\"\n",
    "}\n",
    "\n",
    "arrow2int = {\n",
    "    \"\\u2191\": 1,\n",
    "    \"\\u2193\": -1,\n",
    "    \"=\": 0\n",
    "}\n",
    "\n",
    "def btree2list(binaryDepdency, verbose=0):\n",
    "    def to_list(tree):\n",
    "        treelist = []\n",
    "        if tree.is_tree:\n",
    "            word = tree.val + arrows[tree.mark]\n",
    "            if verbose == 2:\n",
    "                word += str(tree.key)\n",
    "            treelist.append(word)\n",
    "        else:\n",
    "            treelist.append(tree.pos)\n",
    "            word = tree.val.replace('-', ' ') + arrows[tree.mark]\n",
    "            if verbose == 2:\n",
    "                word += str(tree.key)\n",
    "            treelist.append(word)\n",
    "\n",
    "        if tree.left is not None:\n",
    "            treelist.append(to_list(tree.left))\n",
    "\n",
    "        if tree.right is not None:\n",
    "            treelist.append(to_list(tree.right))\n",
    "\n",
    "        return treelist\n",
    "    return to_list(binaryDepdency)\n",
    "\n",
    "def jupyter_draw_nltk_tree(tree):\n",
    "    cf = CanvasFrame()\n",
    "    tc = TreeWidget(cf.canvas(), tree)\n",
    "    tc['node_font'] = 'arial 14 bold'\n",
    "    tc['leaf_font'] = 'arial 14'\n",
    "    tc['node_color'] = '#005990'\n",
    "    tc['leaf_color'] = '#3F8F57'\n",
    "    tc['line_color'] = '#175252'\n",
    "    cf.add_widget(tc, 20, 20)\n",
    "    cf.print_to_file('./tree.ps')\n",
    "    cf.destroy()\n",
    "    command = 'magick convert ./tree.ps ./tree.png'\n",
    "    os.system(command)\n",
    "    display(Image(filename='./tree.png'))\n",
    "    \n",
    "\n",
    "    \n",
    "def jupyter_draw_rsyntax_tree(tree):\n",
    "    font_size = '8'\n",
    "    command = 'rsyntaxtree -s {} \"{}\"'.format(font_size, tree)\n",
    "    os.system(command)\n",
    "    display(Image(filename='./syntree.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G = Ugraph()\n",
    "nounModifiers = {\"det\", \"nummod\", \"amod\",\"obl:tmod\", \"acl:relcl\", \"nmod\", \"nmod:pass\",  \"acl\", \"Prime\",\"cc\"}\n",
    "verbModifiers = {\"advmod\",\"xcomp\",\"advcl\",\"mark\", \"case\", \"aux\"}\n",
    "nounCategories = {\"compound\"} \n",
    "verbs = {\"VBZ\", \"VBP\", \"VBD\", \"VBG\"}\n",
    "modified = {\"NN\", \"PRP\", \"JJ\", \"VB\",\"RB\"}.union(verbs)\n",
    "modifiers = nounModifiers\n",
    "offFocus = {\"expl\"}\n",
    "contents = {\"nsubj\",\"obj\",\"cop\",\"compound\",\"conj\",\"nsubj:pass\",\"obl\"}\n",
    "cont_npos = {\"nsubj\":'nn', \"obj\": 'nn', \"cop\": 'vbz', \"verb\": 'vbz'}\n",
    "mark_toProp = {\"+\": {\"hyponym\",\"synonym\"}, \"-\": {\"hypernym\",\"synonym\"}, \"=\": {\"synonym\"}}\n",
    "clause_prop = {\"which\", \"that\", \"who\"}\n",
    "be_verbs = {\"is\", \"am\", \"are\", \"be\",\"was\",\"were\"}\n",
    "directions = {0: \"lexical\", 1: \"phrasal\", 2: \"syntatic_variation\", 3: \"implicative\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantifier_replacement = {\n",
    "    \"a-few\": \"some\",\n",
    "    \"a-few of the\": \"some\",\n",
    "    \"none-of-the\": \"no\",\n",
    "    \"all-of-the\": \"all\",\n",
    "    \"some-of-the\": \"some\",\n",
    "    \"most-of-the\": \"most\",\n",
    "    \"many-of-the\": \"many\",\n",
    "    \"several-of-the\": \"several\",\n",
    "    \"some-but-not-all\": \"some\",\n",
    "    \"at-most\": \"no\",\n",
    "    \"at-least\": \"some\",\n",
    "    \"more-than\": \"some\",\n",
    "    \"less-than\": \"no\",\n",
    "    \"no-longer\": \"not\",\n",
    "    \"a-lot-of\": \"some\",\n",
    "    \"lots-of\": \"some\",\n",
    "    \"each of the\": \"each\",\n",
    "    \"A-few\": \"Some\",\n",
    "    \"A-few of the\": \"Some\",\n",
    "    \"None-of-the\": \"No\",\n",
    "    \"All-of-the\": \"All\",\n",
    "    \"Some-of-the\": \"Some\",\n",
    "    \"Most-of-the\": \"Most\",\n",
    "    \"Many-of-the\": \"Many\",\n",
    "    \"Several-of-the\": \"Several\",\n",
    "    \"Some-but-not-all\": \"Some\",\n",
    "    \"At-most\": \"No\",\n",
    "    \"At-least\": \"Some\",\n",
    "    \"More-than\": \"Some\",\n",
    "    \"Less-than\": \"No\",\n",
    "    \"No-longer\": \"Not\",\n",
    "    \"A-lot-of\": \"Some\",\n",
    "    \"Lots-of\": \"Some\",\n",
    "    \"Each of the\": \"Each\",\n",
    "    \"hardly-ever\": \"never\",\n",
    "    \"Even-if\": \"If\",\n",
    "    \"even-if\": \"if\",\n",
    "    \"not-every\": \"every\",\n",
    "    \"not-some\": \"some\",\n",
    "    \"not-all\": \"all\",\n",
    "    \"not-each\": \"each\",\n",
    "    \"Not-every\": \"every\",\n",
    "    \"Not-some\": \"some\",\n",
    "    \"Not-all\": \"all\",\n",
    "    \"Not-each\": \"each\",\n",
    "\n",
    "    \"after-all\": \"after-all\",\n",
    "    \"out-of\": \"out-of\",\n",
    "    \"hardly-ever\": \"never\",\n",
    "    \"no-longer\": \"no-longer\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cnode:\n",
    "    def __init__(self,prop,word,npos, mark):\n",
    "        self.nexts = set()\n",
    "        self.prop = prop\n",
    "        self.isRoot = False\n",
    "        self.isRelation = False\n",
    "        self.modifiers = set() \n",
    "        self.index = -2\n",
    "        self.related = []\n",
    "        self.word = word\n",
    "        self.npos = npos\n",
    "        self.mark = mark\n",
    "        self.phrases = set()\n",
    "        self.pair = -1\n",
    "        self.pairParts = dict()\n",
    "        self.start = -1\n",
    "        self.end = -1\n",
    "        self.nodes = set()\n",
    "        self.cc = None\n",
    "        self.aligned = []\n",
    "        self.isComp = False\n",
    "        #self.alignedBy = []\n",
    "        self.parent = None\n",
    "        self.explMain = False\n",
    "    def add_Unode(self, node):\n",
    "        #print(node.prop)\n",
    "        if(self.isRoot):\n",
    "            if(node.prop == \"obl\"):\n",
    "                node.prop = \"obj\"\n",
    "            self.nexts[node.prop].add(node)\n",
    "        else:\n",
    "            self.nexts[\"all\"].add(node)\n",
    "    def addNode(self, node):\n",
    "        return\n",
    "    def add_modifier(self, modifierNode):\n",
    "        self.modifiers.add(modifierNode)\n",
    "    def getText(self):\n",
    "        return\n",
    "    \n",
    "    def get_magicText(self):\n",
    "        return \"(a_b)\"\n",
    "    def get_magicTextOld(self):\n",
    "        connected_info = \"\"\n",
    "        if(self.isRoot):\n",
    "            for key in self.nexts.keys():\n",
    "                component = \"\"\n",
    "                if(key != \"all\"):\n",
    "                    print(key)\n",
    "                    for keyItem in self.nexts[key]:\n",
    "                        component += \" (\" + keyItem.get_magicText() + \")\"\n",
    "                    component = \"(\" + key + \" \" + component + \")\"\n",
    "                connected_info += component\n",
    "            return \"(\" + connected_info + \")\"\n",
    "        else:\n",
    "            for node in self.nexts[\"all\"]:\n",
    "                if(node != None):\n",
    "                    #print(\"111\")\n",
    "                    connected_info +=  \"(\" + node.get_magicText() + \")\"\n",
    "            if(self.nexts[\"all\"] == set()):\n",
    "                if(self.pair != -1):\n",
    "                    return self.word.replace(' ', '_') + str(self.pair)\n",
    "                return self.word.replace(' ', '_')\n",
    "            if(self.pair != -1):\n",
    "                    return self.word.replace(' ', '_') + str(self.pair) + connected_info\n",
    "            return  self.word.replace(' ', '_') + connected_info\n",
    "    def addNum(self,num):\n",
    "        self.pair = num\n",
    "    def addPart(self, newNode, type1):\n",
    "        if(type1 not in self.pairParts):\n",
    "            self.pairParts[type1] = set()\n",
    "        self.pairParts[type1].add(newNode)\n",
    "    def getParts(self):\n",
    "        ### return verb-obj subParts now\n",
    "        return self.pairParts[\"obj\"]\n",
    "    def addCC(self,node):\n",
    "        self.cc = node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cgraph:\n",
    "    def __init__(self, rootNode):\n",
    "        self.root = rootNode\n",
    "        self.root.isRoot = True\n",
    "        self.concepts = set()\n",
    "        self.relations = set()\n",
    "        self.relDeps = []\n",
    "        self.nodes = []\n",
    "        self.contentSet = set()\n",
    "        self.chunks = set()\n",
    "        self.Pairs = dict()\n",
    "        self.Pairs[\"nsubj\"] = dict()\n",
    "        self.Pairs[\"obj\"] = dict()\n",
    "        self.align_log = []\n",
    "        self.expl = False\n",
    "        self.passive = False\n",
    "    def add_node(self,node):\n",
    "        self.nodes.add(node)\n",
    "        self.root.addNode(node)\n",
    "    def add_edge(self, node1, node2):\n",
    "        #if(node1.isRoot):\n",
    "        #    self.contentSet.add(node2.word)\n",
    "        #    node2.isComp = True\n",
    "        node1.nexts.add(node2)\n",
    "        node2.parent = node1\n",
    "    def indexNodes(self):\n",
    "        output = \"\"\n",
    "        for node in self.nodes:\n",
    "            output += node.word\n",
    "            output += \"[\"\n",
    "            output += str(node.index)\n",
    "            output += \"]\"\n",
    "            output += \" \"\n",
    "        return output.strip()\n",
    "    \n",
    "    def print_text(self):\n",
    "        relations = []\n",
    "        for node in self.nodes:\n",
    "            for nextItem in node.nexts:\n",
    "                relations.append([node.word, nextItem.word, node.index, nextItem.index])\n",
    "        #print(relations)\n",
    "        return relations\n",
    "                \n",
    "    def print_content(self, set1,inword=True):\n",
    "        output = []\n",
    "        if(inword==False):\n",
    "            for item in set1:\n",
    "                output.append(item.index)\n",
    "        else:\n",
    "            for item in set1:\n",
    "                output.append(item.word)\n",
    "        return output\n",
    "    def print_modifiers(self, mode = True):\n",
    "        modifiers = dict()\n",
    "        for node in self.nodes:\n",
    "            if(node.modifiers != set()):\n",
    "                if(mode):\n",
    "                    modifiers[node.word+str(node.index)] = []\n",
    "                    for modifier in node.modifiers:\n",
    "                        modifiers[node.word+str(node.index)].append(modifier.word)\n",
    "                else:\n",
    "                    modifiers[node.index] = []\n",
    "                    for modifier in node.modifiers:\n",
    "                        modifiers[node.index].append(modifier.index)\n",
    "               \n",
    "        return modifiers\n",
    "        \n",
    "    def contains(self, word_assigned):\n",
    "        return word_assigned in self.contentSet\n",
    "    def get_magicText(self):\n",
    "        return self.root.get_magicText()\n",
    "    def addPair(self, newNode, num,type1):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Concept:\n",
    "    def __init__(self, data):\n",
    "        self.data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphFactoryPipeline:\n",
    "    def __init__(self, verbose=0, parser=\"gum\"):\n",
    "        self.parser = parser\n",
    "        self.binarizer = Binarizer()\n",
    "        self.exceptioned = []\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.concept_pos = [\"NN\", \"NNS\", \"NNP\", \"NNPS\", \"PRP\", \"PRP$\"]\n",
    "        self.relation_pos = [\"VB\", \"VBD\", \"VBG\", \"VBN\", \n",
    "                             \"VBP\", \"VBZ\", \"TO\", \"IN\"]\n",
    "        self.modifiers = {\"det\", \"nummod\", \"amod\",\"obl:tmod\", \"nmod\", \"nmod:pass\", \"acl\", \"Prime\", \"fixed\",\n",
    "                          \"advmod\", \"aux\", \"paratxis\", \"ccomp\"}\n",
    "\n",
    "        self.modifier_relation = {\n",
    "            \"NN\": [\"amod\", \"nmod\", \"acl:relcl\", \"fixed\", \"compound\", \"det\", \"nmod:poss\", \"conj\", \"nummod\"],\n",
    "            \"VB\": [\"advmod\", \"acl\", \"obl\", \"xcomp\", \"advcl\", \"obl:tmod\", \"parataxis\", \"obj\",\"ccomp\"]\n",
    "        }\n",
    "        self.concept_dep = {\"nsubj\": 0,\"obj\":0,\"cop\":1,\"conj\":1,\"nsubj:pass\":1, \"obl\":0}\n",
    "        self.relation_dep = {\"xcomp\":2,\"advcl\":0,\"mark\":0, \"case\":0, \"cop\":0, \"obj\":1, \"obl\":1,\"acl:relcl\":1}\n",
    "        self.concept = None\n",
    "        self.dataSet = dict()\n",
    "        self.dictionary = dict()\n",
    "        self.numSentence = 0;\n",
    "\n",
    "    def extract_concepts_relation(self, deps, G):\n",
    "        concepts = G.concepts\n",
    "        relation = G.relations\n",
    "        nodes = G.nodes\n",
    "        \n",
    "        for dep in deps:\n",
    "            if dep[0] in self.concept_dep:\n",
    "                if(dep[0] in [\"obj\", \"obl\"]):\n",
    "                    nodeFrom = nodes[dep[2]-1]\n",
    "                    nodeTo = nodes[dep[1]-1]\n",
    "                    \n",
    "                else:\n",
    "                    nodeFrom = nodes[dep[1]-1]\n",
    "                    nodeTo = nodes[dep[2]-1]\n",
    "                nodeFrom.nexts.add(nodeTo)\n",
    "                G.relDeps.append([dep[0], nodeFrom, nodeTo])\n",
    "                type1 = self.concept_dep[dep[0]]\n",
    "                if(type1==2):\n",
    "                    concepts.add(nodes[dep[1]-1])\n",
    "                    concepts.add(nodes[dep[2]-1])\n",
    "                else:\n",
    "                    concepts.add(nodes[dep[type1+1]-1])\n",
    "            if dep[0] in self.relation_dep:\n",
    "                type1 = self.relation_dep[dep[0]]\n",
    "                if(dep[0] in (self.concept_dep.keys() & self.relation_dep.keys())):\n",
    "                    pass\n",
    "                else:\n",
    "                    if(type1 ==0):\n",
    "                        nodeFrom = nodes[dep[1]-1]\n",
    "                        nodeTo = nodes[dep[2]-1]\n",
    "                        \n",
    "                    else:\n",
    "                        nodeFrom = nodes[dep[2]-1]\n",
    "                        nodeTo = nodes[dep[1]-1]\n",
    "                    nodeFrom.nexts.add(nodeTo)\n",
    "                    G.relDeps.append([dep[0], nodeFrom, nodeTo])\n",
    "                if(type1==2):\n",
    "                    relation.add(nodes[dep[1]-1])\n",
    "                    relation.add(nodes[dep[2]-1])\n",
    "                else:\n",
    "                    relation.add(nodes[dep[type1+1]-1])\n",
    "       # return concepts, relation\n",
    "    \n",
    "    def add_modifiers(self, deps, G):\n",
    "        nodes = G.nodes\n",
    "        for dep in deps:\n",
    "            if(dep[0] in self.modifiers):\n",
    "                nodes[dep[2]-1].modifiers.add(nodes[dep[1]-1])\n",
    "                \n",
    "                \n",
    "    def down_right(self, tree):\n",
    "        if(tree.right == None):\n",
    "            return tree\n",
    "        return self.down_right(tree.right)\n",
    "\n",
    "    def down_left(self, tree):\n",
    "        if(tree.left == None):\n",
    "            return tree\n",
    "        return self.down_left(tree.left)\n",
    "    \n",
    "    def collect_modifiers(self, tree, sent_set, mod_type=\"NN\"):\n",
    "        leaves = []\n",
    "        if tree.is_tree:\n",
    "            if tree.val in [\"mark\", \"case\", \"compound\", \"flat\", \"nmod\"]:\n",
    "                leaves.append(\n",
    "                    (list(tree.right.sorted_leaves().popkeys()),\n",
    "                    self.down_right(tree.left).val)\n",
    "                )\n",
    "            if tree.val in self.modifier_relation[mod_type]:\n",
    "                leaves.append(\n",
    "                    (list(tree.left.sorted_leaves().popkeys()),\n",
    "                    self.down_right(tree.right).val)\n",
    "                )\n",
    "\n",
    "            for leave in leaves:\n",
    "                if len(leave) > 0 and len(leave) < 10:\n",
    "                    head = leave[1]\n",
    "                    modifier = ' '.join([x[0] for x in leave[0]])\n",
    "                    if tree.val in sent_set:\n",
    "                        sent_set[tree.val].append({'head': head,'mod': modifier})\n",
    "                    else:\n",
    "                        sent_set[tree.val] = [{'head': head,'mod': modifier}]\n",
    "            \n",
    "            self.collect_modifiers(tree.left, sent_set, mod_type)\n",
    "            self.collect_modifiers(tree.right, sent_set, mod_type)\n",
    "            \n",
    "    def unpack_verbComp(self, G):\n",
    "        for rel in G.relDeps:\n",
    "            if(rel[0] in [\"obl\", \"xcomp\"]):\n",
    "                nodeTo = rel[2]\n",
    "                for rel2 in G.relDeps:\n",
    "                    if(rel2[2] == nodeTo and rel2[0] in [\"mark\", \"case\"]):\n",
    "                        #print(2222)\n",
    "                        rel[2] = rel2[1]\n",
    "                        try:\n",
    "                            rel[1].nexts.remove(nodeTo)\n",
    "                        except:\n",
    "                            pass\n",
    "                        rel[1].nexts.add(rel2[1])\n",
    "    \n",
    "    def init_graph(self, parsed, sent):\n",
    "        G = Cgraph(Cnode(\"Root\", \"Root\", \"Root\", \"Root\"))\n",
    "        i = 1\n",
    "        for index in parsed[2].keys():\n",
    "            node1 = Cnode(\"\", parsed[2][index][0], parsed[2][index][1], \"\")\n",
    "            node1.index = index\n",
    "            i+=1\n",
    "            G.nodes.append(node1)\n",
    "        return G\n",
    "\n",
    "    def run_binarization(self, parsed, sentence):\n",
    "        self.binarizer.parse_table = parsed[0]\n",
    "        self.binarizer.postag = parsed[1]\n",
    "        self.binarizer.words = parsed[2]\n",
    "\n",
    "        if self.verbose == 2:\n",
    "            print()\n",
    "            print(parsed[0])\n",
    "            print()\n",
    "            print(parsed[1])\n",
    "            print()\n",
    "            print(replaced)\n",
    "\n",
    "        self.binarizer.replaced = []\n",
    "        binary_dep, relation = self.binarizer.binarization()\n",
    "        if self.verbose == 2:\n",
    "            self.postprocess(binary_dep)\n",
    "        return binary_dep, relation\n",
    "    \n",
    "    def sent2tree(self, sentence):\n",
    "        parsed = dependency_parse(sentence, self.parser)\n",
    "        #print(parsed)\n",
    "        concepts,relations = self.extract_concepts_relation(parsed[1])\n",
    "        binary_dep, _ = self.run_binarization(parsed, sentence)\n",
    "        return binary_dep, parsed, concepts, relations\n",
    "\n",
    "    def single_polarization(self, sentence):\n",
    "        \n",
    "        sentence = sentence.replace(\".\", \"\").replace(\",\", \"\")\n",
    "        try:\n",
    "            parsed = dependency_parse(sentence, self.parser)\n",
    "        except:\n",
    "            return\n",
    "        #print(parsed)\n",
    "        G = self.init_graph(parsed, sentence)\n",
    "        self.extract_concepts_relation(parsed[0], G)\n",
    "        self.add_modifiers(parsed[0], G)\n",
    "        \n",
    "        #binary_dep, parsed, concepts, relations = self.sent2tree(sentence)\n",
    "        modifiers = {}\n",
    "        #self.collect_modifiers(binary_dep, modifiers)\n",
    "        self.unpack_verbComp(G)\n",
    "        G.print_text()\n",
    "        \n",
    "        return {\n",
    "            'sentence': sentence,\n",
    "            'indexed': G.indexNodes(),\n",
    "            'concepts': G.print_content(G.concepts),\n",
    "            'conceptIndexed': G.print_content(G.concepts, False),\n",
    "            'relations': G.print_content(G.relations),\n",
    "            'relationIndexed': G.print_content(G.relations, False),\n",
    "            'relationLogs': G.print_text(),\n",
    "            'modifiers': G.print_modifiers(),\n",
    "            'modifiersIndexed': G.print_modifiers(False),\n",
    "            'parsed': parsed[2] \n",
    "        }\n",
    "\n",
    "        def postprocess(self, tree, svg=False):\n",
    "            sexpression = btree2list(tree, 0)\n",
    "            if not svg:\n",
    "                sexpression = '[%s]' % ', '.join(\n",
    "                    map(str, sexpression)).replace(\",\", \" \").replace(\"'\", \"\")\n",
    "            # print(sexpression)\n",
    "            # jupyter_draw_rsyntax_tree(polarized)\n",
    "            # btreeViz = Tree.fromstring(polarized.replace('[', '(').replace(']', ')'))\n",
    "            # jupyter_draw_nltk_tree(btreeViz)\n",
    "            return sexpression \n",
    "        \n",
    "    def initiateSetting(self):\n",
    "        self.dataSet = dict()\n",
    "        self.dictionary = dict()\n",
    "        self.numSentence = 0;\n",
    "        \n",
    "    def parseSentence(self, filename, num):\n",
    "        output = set()\n",
    "        with open(filename) as snli:\n",
    "            snlis = list(snli)\n",
    "        for sent in snlis:\n",
    "            if(len(output) >= num):\n",
    "                break\n",
    "            output.add(json.loads(sent)['sentence1'])\n",
    "        return output\n",
    "    \n",
    "    def generateData(self, num):\n",
    "        data = self.parseSentence(\"./snli_1.0_train.jsonl\", num) #./data/SNLI/snli_1.0/\n",
    "        #print(data)\n",
    "        self.initiateSetting()\n",
    "        with open(\"./relation_data.json\", 'w') as jsonFile:\n",
    "            with open(\"./relation_script3.json\", \"w\") as jsonScript:\n",
    "                index1 = 0\n",
    "                for sent in data:\n",
    "                    if(index1 >= num):\n",
    "                        break\n",
    "                    singleDict = self.single_polarization(sent)\n",
    "                    #print(singleDict)\n",
    "                    if(singleDict != None):\n",
    "                        self.dictionary[self.numSentence] = singleDict\n",
    "                        self.numSentence+=1\n",
    "                        #print(index1)\n",
    "                        index1+=1\n",
    "                \n",
    "                json.dump(self.dataSet, jsonFile)\n",
    "                json.dump(self.dictionary, jsonScript, indent=2, separators = (', \\n', ': '))\n",
    "    def script_to_graph(self, script):\n",
    "        G = init_graph([\"\",\"\",script['parsed']], script['sentence'])\n",
    "        for index1 in script['conceptIndexed']:\n",
    "            G.concepts.add(G.nodes[index])\n",
    "        for index2 in script['relationIndexed']:\n",
    "            G.nodes[index].isRelation = True\n",
    "            G.relations.add(G.nodes[index])\n",
    "        for mod in script['modifiersIndexed'].keys():\n",
    "            for modifier in script['modifiersIndexed'][mod]:\n",
    "                \n",
    "                G.nodes[mod].modifiers.add(G.nodes[modifier])\n",
    "        for log in script['relationLogs']:\n",
    "            G.nodes[str(log[2])].nexts.add(G.nodes[str(log[3])])\n",
    "        return G\n",
    "    def to_nn_input(self, script):\n",
    "        return\n",
    "       \n",
    "         \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_factory = GraphFactoryPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I', 'sleeping'], ['sleeping', 'on'], ['on', 'bed']]\n",
      "\n",
      "Output: \n",
      "\n",
      "Concepts:  ['bed', 'I']\n",
      "Relations:  ['on', 'sleeping']\n",
      "Modifiers:  {'sleeping3': ['am'], 'bed6': ['the']}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2)  \n",
    "\n",
    "sentence = \"I am sleeping on the bed\"#\"That store sales some beautiful flowers to attract customers.\"\n",
    "graph = graph_factory.single_polarization(sentence)\n",
    "#print(tree1.left.val)\n",
    "#graph_factory.tree_toGraph(tree1)\n",
    "#print(Tree.fromstring(\"(a(b))\"))\n",
    "#jupyter_draw_nltk_tree(Tree.fromstring(\"(a (b c))\"))\n",
    "print(\"\\nOutput: \\n\")\n",
    "print('Concepts: ', graph['concepts'])\n",
    "print('Relations: ', graph['relations'])\n",
    "print('Modifiers: ', graph['modifiers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "graph_factory.generateData(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['det', 1, 3], ['amod', 2, 3], ['nsubj', 3, 5], ['aux', 4, 5], ['root', 5, 'root'], ['amod', 6, 7], ['obj', 7, 5], ['case', 8, 10], ['det', 9, 10], ['obl', 10, 5]], {'An': (1, 'DT'), 'older': (2, 'JJR'), 'man': (3, 'NN'), 'is': (4, 'VBZ'), 'drinking': (5, 'VBG'), 'orange': (6, 'JJ'), 'juice': (7, 'NN'), 'at': (8, 'IN'), 'a': (9, 'DT'), 'restaurant': (10, 'NN')}, {1: ('An', 'DT'), 2: ('older', 'JJR'), 3: ('man', 'NN'), 4: ('is', 'VBZ'), 5: ('drinking', 'VBG'), 6: ('orange', 'JJ'), 7: ('juice', 'NN'), 8: ('at', 'IN'), 9: ('a', 'DT'), 10: ('restaurant', 'NN')})\n",
      "2222\n",
      "[['man', 'drinking'], ['drinking', 'juice'], ['drinking', 'at'], ['at', 'restaurant']]\n",
      "\n",
      "Output: \n",
      "\n",
      "Concept:  ['juice', 'restaurant', 'man']\n",
      "Relations:  ['at', 'drinking']\n",
      "Modifiers:  {'man3': ['An', 'older'], 'drinking5': ['is'], 'juice7': ['orange'], 'restaurant10': ['a']}\n"
     ]
    }
   ],
   "source": [
    "sentence = \"An older man is drinking orange juice at a restaurant\"\n",
    "graph = graph_factory.single_polarization(sentence)\n",
    "print(\"\\nOutput: \\n\")\n",
    "print('Concept: ', graph['concepts'])\n",
    "print('Relations: ', graph['relations'])\n",
    "print('Modifiers: ', graph['modifiers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['nmod:poss', 1, 4], ['case-after', 2, 1], ['compound', 3, 4], ['root', 4, 'root'], ['aux:pass', 5, 6], ['acl', 6, 4], ['mark', 7, 10], ['det', 8, 10], ['compound', 9, 10], ['advcl', 10, 6], ['case', 11, 13], ['det', 12, 13], ['nmod', 13, 10]], {'Children': (1, 'NNS'), \"'s\": (2, 'POS'), 'soccer': (3, 'NN'), 'game': (4, 'NN'), 'being': (5, 'VBG'), 'played': (6, 'VBN'), 'while': (7, 'IN'), 'the': (12, 'DT'), 'sun': (9, 'NN'), 'sets': (10, 'NNS'), 'in': (11, 'IN'), 'background': (13, 'NN')}, {1: ('Children', 'NNS'), 2: (\"'s\", 'POS'), 3: ('soccer', 'NN'), 4: ('game', 'NN'), 5: ('being', 'VBG'), 6: ('played', 'VBN'), 7: ('while', 'IN'), 8: ('the', 'DT'), 9: ('sun', 'NN'), 10: ('sets', 'NNS'), 11: ('in', 'IN'), 12: ('the', 'DT'), 13: ('background', 'NN')})\n",
      "10\n",
      "6\n",
      "13\n",
      "\n",
      "Output: \n",
      "\n",
      "Concept:  []\n",
      "Relations:  ['sets', 'in', 'while']\n",
      "Modifiers:  {'game4': ['played'], 'sets10': ['the', 'background'], 'background13': ['the']}\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Children's soccer game being played, while the sun sets in the background\"\n",
    "graph = graph_factory.single_polarization(sentence)\n",
    "print(\"\\nOutput: \\n\")\n",
    "print('Concept: ', graph['concepts'])\n",
    "print('Relations: ', graph['relations'])\n",
    "print('Modifiers: ', graph['modifiers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'awareness': {'value': {'datatype': 'int', 'categories': [0, 1, 2, 3, 4], 'ordered': True}, 'confidence': {'datatype': 'int', 'categories': [0, 1], 'ordered': False}, 'annotators': ['protoroles-annotator-0', 'protoroles-annotator-1', 'protoroles-annotator-10', 'protoroles-annotator-11', 'protoroles-annotator-12', 'protoroles-annotator-13', 'protoroles-annotator-14', 'protoroles-annotator-15', 'protoroles-annotator-16', 'protoroles-annotator-17', 'protoroles-annotator-18', 'protoroles-annotator-19', 'protoroles-annotator-2', 'protoroles-annotator-20', 'protoroles-annotator-21', 'protoroles-annotator-22', 'protoroles-annotator-23', 'protoroles-annotator-24', 'protoroles-annotator-25', 'protoroles-annotator-26', 'protoroles-annotator-27', 'protoroles-annotator-28', 'protoroles-annotator-29', 'protoroles-annotator-3', 'protoroles-annotator-30', 'protoroles-annotator-31', 'protoroles-annotator-32', 'protoroles-annotator-33', 'protoroles-annotator-34', 'protoroles-annotator-35', 'protoroles-annotator-36', 'protoroles-annotator-37', 'protoroles-annotator-38', 'protoroles-annotator-39', 'protoroles-annotator-4', 'protoroles-annotator-40', 'protoroles-annotator-42', 'protoroles-annotator-43', 'protoroles-annotator-44', 'protoroles-annotator-45', 'protoroles-annotator-5', 'protoroles-annotator-6', 'protoroles-annotator-7', 'protoroles-annotator-8', 'protoroles-annotator-9']}, 'change_of_location': {'value': {'datatype': 'int', 'categories': [0, 1, 2, 3, 4], 'ordered': True}, 'confidence': {'datatype': 'int', 'categories': [0, 1], 'ordered': False}, 'annotators': ['protoroles-annotator-0', 'protoroles-annotator-1', 'protoroles-annotator-10', 'protoroles-annotator-11', 'protoroles-annotator-12', 'protoroles-annotator-13', 'protoroles-annotator-14', 'protoroles-annotator-15', 'protoroles-annotator-16', 'protoroles-annotator-17', 'protoroles-annotator-18', 'protoroles-annotator-19', 'protoroles-annotator-2', 'protoroles-annotator-20', 'protoroles-annotator-21', 'protoroles-annotator-22', 'protoroles-annotator-23', 'protoroles-annotator-24', 'protoroles-annotator-25', 'protoroles-annotator-26', 'protoroles-annotator-27', 'protoroles-annotator-28', 'protoroles-annotator-29', 'protoroles-annotator-3', 'protoroles-annotator-30', 'protoroles-annotator-31', 'protoroles-annotator-32', 'protoroles-annotator-33', 'protoroles-annotator-34', 'protoroles-annotator-35', 'protoroles-annotator-36', 'protoroles-annotator-37', 'protoroles-annotator-38', 'protoroles-annotator-39', 'protoroles-annotator-4', 'protoroles-annotator-40', 'protoroles-annotator-42', 'protoroles-annotator-43', 'protoroles-annotator-44', 'protoroles-annotator-45', 'protoroles-annotator-5', 'protoroles-annotator-6', 'protoroles-annotator-7', 'protoroles-annotator-8', 'protoroles-annotator-9']}, 'change_of_possession': {'value': {'datatype': 'int', 'categories': [0, 1, 2, 3, 4], 'ordered': True}, 'confidence': {'datatype': 'int', 'categories': [0, 1], 'ordered': False}, 'annotators': ['protoroles-annotator-0', 'protoroles-annotator-1', 'protoroles-annotator-10', 'protoroles-annotator-11', 'protoroles-annotator-12', 'protoroles-annotator-13', 'protoroles-annotator-14', 'protoroles-annotator-15', 'protoroles-annotator-16', 'protoroles-annotator-17', 'protoroles-annotator-18', 'protoroles-annotator-19', 'protoroles-annotator-2', 'protoroles-annotator-20', 'protoroles-annotator-21', 'protoroles-annotator-22', 'protoroles-annotator-23', 'protoroles-annotator-24', 'protoroles-annotator-25', 'protoroles-annotator-26', 'protoroles-annotator-27', 'protoroles-annotator-28', 'protoroles-annotator-29', 'protoroles-annotator-3', 'protoroles-annotator-30', 'protoroles-annotator-31', 'protoroles-annotator-32', 'protoroles-annotator-33', 'protoroles-annotator-34', 'protoroles-annotator-35', 'protoroles-annotator-36', 'protoroles-annotator-37', 'protoroles-annotator-38', 'protoroles-annotator-39', 'protoroles-annotator-4', 'protoroles-annotator-40', 'protoroles-annotator-42', 'protoroles-annotator-43', 'protoroles-annotator-44', 'protoroles-annotator-45', 'protoroles-annotator-5', 'protoroles-annotator-6', 'protoroles-annotator-7', 'protoroles-annotator-8', 'protoroles-annotator-9']}, 'change_of_state': {'value': {'datatype': 'int', 'categories': [0, 1, 2, 3, 4], 'ordered': True}, 'confidence': {'datatype': 'int', 'categories': [0, 1], 'ordered': False}, 'annotators': ['protoroles-annotator-0', 'protoroles-annotator-1', 'protoroles-annotator-10', 'protoroles-annotator-11', 'protoroles-annotator-12', 'protoroles-annotator-13', 'protoroles-annotator-14', 'protoroles-annotator-15', 'protoroles-annotator-16', 'protoroles-annotator-17', 'protoroles-annotator-18', 'protoroles-annotator-19', 'protoroles-annotator-2', 'protoroles-annotator-20', 'protoroles-annotator-21', 'protoroles-annotator-22', 'protoroles-annotator-23', 'protoroles-annotator-24', 'protoroles-annotator-25', 'protoroles-annotator-26', 'protoroles-annotator-27', 'protoroles-annotator-28', 'protoroles-annotator-29', 'protoroles-annotator-3', 'protoroles-annotator-30', 'protoroles-annotator-31', 'protoroles-annotator-32', 'protoroles-annotator-33', 'protoroles-annotator-34', 'protoroles-annotator-35', 'protoroles-annotator-36', 'protoroles-annotator-37', 'protoroles-annotator-38', 'protoroles-annotator-39', 'protoroles-annotator-4', 'protoroles-annotator-40', 'protoroles-annotator-42', 'protoroles-annotator-43', 'protoroles-annotator-44', 'protoroles-annotator-45', 'protoroles-annotator-5', 'protoroles-annotator-6', 'protoroles-annotator-7', 'protoroles-annotator-8', 'protoroles-annotator-9']}, 'change_of_state_continuous': {'value': {'datatype': 'int', 'categories': [0, 1, 2, 3, 4], 'ordered': True}, 'confidence': {'datatype': 'int', 'categories': [0, 1], 'ordered': False}, 'annotators': ['protoroles-annotator-0', 'protoroles-annotator-1', 'protoroles-annotator-10', 'protoroles-annotator-11', 'protoroles-annotator-12', 'protoroles-annotator-13', 'protoroles-annotator-14', 'protoroles-annotator-15', 'protoroles-annotator-16', 'protoroles-annotator-17', 'protoroles-annotator-18', 'protoroles-annotator-19', 'protoroles-annotator-2', 'protoroles-annotator-20', 'protoroles-annotator-21', 'protoroles-annotator-22', 'protoroles-annotator-23', 'protoroles-annotator-24', 'protoroles-annotator-25', 'protoroles-annotator-26', 'protoroles-annotator-27', 'protoroles-annotator-28', 'protoroles-annotator-29', 'protoroles-annotator-3', 'protoroles-annotator-30', 'protoroles-annotator-31', 'protoroles-annotator-32', 'protoroles-annotator-33', 'protoroles-annotator-34', 'protoroles-annotator-35', 'protoroles-annotator-36', 'protoroles-annotator-37', 'protoroles-annotator-38', 'protoroles-annotator-39', 'protoroles-annotator-4', 'protoroles-annotator-40', 'protoroles-annotator-42', 'protoroles-annotator-43', 'protoroles-annotator-44', 'protoroles-annotator-45', 'protoroles-annotator-5', 'protoroles-annotator-6', 'protoroles-annotator-7', 'protoroles-annotator-8', 'protoroles-annotator-9']}, 'existed_after': {'value': {'datatype': 'int', 'categories': [0, 1, 2, 3, 4], 'ordered': True}, 'confidence': {'datatype': 'int', 'categories': [0, 1], 'ordered': False}, 'annotators': ['protoroles-annotator-0', 'protoroles-annotator-1', 'protoroles-annotator-10', 'protoroles-annotator-11', 'protoroles-annotator-12', 'protoroles-annotator-13', 'protoroles-annotator-14', 'protoroles-annotator-15', 'protoroles-annotator-16', 'protoroles-annotator-17', 'protoroles-annotator-18', 'protoroles-annotator-19', 'protoroles-annotator-2', 'protoroles-annotator-20', 'protoroles-annotator-21', 'protoroles-annotator-22', 'protoroles-annotator-23', 'protoroles-annotator-24', 'protoroles-annotator-25', 'protoroles-annotator-26', 'protoroles-annotator-27', 'protoroles-annotator-28', 'protoroles-annotator-29', 'protoroles-annotator-3', 'protoroles-annotator-30', 'protoroles-annotator-31', 'protoroles-annotator-32', 'protoroles-annotator-33', 'protoroles-annotator-34', 'protoroles-annotator-35', 'protoroles-annotator-36', 'protoroles-annotator-37', 'protoroles-annotator-38', 'protoroles-annotator-39', 'protoroles-annotator-4', 'protoroles-annotator-40', 'protoroles-annotator-42', 'protoroles-annotator-43', 'protoroles-annotator-44', 'protoroles-annotator-45', 'protoroles-annotator-5', 'protoroles-annotator-6', 'protoroles-annotator-7', 'protoroles-annotator-8', 'protoroles-annotator-9']}, 'existed_before': {'value': {'datatype': 'int', 'categories': [0, 1, 2, 3, 4], 'ordered': True}, 'confidence': {'datatype': 'int', 'categories': [0, 1], 'ordered': False}, 'annotators': ['protoroles-annotator-0', 'protoroles-annotator-1', 'protoroles-annotator-10', 'protoroles-annotator-11', 'protoroles-annotator-12', 'protoroles-annotator-13', 'protoroles-annotator-14', 'protoroles-annotator-15', 'protoroles-annotator-16', 'protoroles-annotator-17', 'protoroles-annotator-18', 'protoroles-annotator-19', 'protoroles-annotator-2', 'protoroles-annotator-20', 'protoroles-annotator-21', 'protoroles-annotator-22', 'protoroles-annotator-23', 'protoroles-annotator-24', 'protoroles-annotator-25', 'protoroles-annotator-26', 'protoroles-annotator-27', 'protoroles-annotator-28', 'protoroles-annotator-29', 'protoroles-annotator-3', 'protoroles-annotator-30', 'protoroles-annotator-31', 'protoroles-annotator-32', 'protoroles-annotator-33', 'protoroles-annotator-34', 'protoroles-annotator-35', 'protoroles-annotator-36', 'protoroles-annotator-37', 'protoroles-annotator-38', 'protoroles-annotator-39', 'protoroles-annotator-4', 'protoroles-annotator-40', 'protoroles-annotator-42', 'protoroles-annotator-43', 'protoroles-annotator-44', 'protoroles-annotator-45', 'protoroles-annotator-5', 'protoroles-annotator-6', 'protoroles-annotator-7', 'protoroles-annotator-8', 'protoroles-annotator-9']}, 'existed_during': {'value': {'datatype': 'int', 'categories': [0, 1, 2, 3, 4], 'ordered': True}, 'confidence': {'datatype': 'int', 'categories': [0, 1], 'ordered': False}, 'annotators': ['protoroles-annotator-0', 'protoroles-annotator-1', 'protoroles-annotator-10', 'protoroles-annotator-11', 'protoroles-annotator-12', 'protoroles-annotator-13', 'protoroles-annotator-14', 'protoroles-annotator-15', 'protoroles-annotator-16', 'protoroles-annotator-17', 'protoroles-annotator-18', 'protoroles-annotator-19', 'protoroles-annotator-2', 'protoroles-annotator-20', 'protoroles-annotator-21', 'protoroles-annotator-22', 'protoroles-annotator-23', 'protoroles-annotator-24', 'protoroles-annotator-25', 'protoroles-annotator-26', 'protoroles-annotator-27', 'protoroles-annotator-28', 'protoroles-annotator-29', 'protoroles-annotator-3', 'protoroles-annotator-30', 'protoroles-annotator-31', 'protoroles-annotator-32', 'protoroles-annotator-33', 'protoroles-annotator-34', 'protoroles-annotator-35', 'protoroles-annotator-36', 'protoroles-annotator-37', 'protoroles-annotator-38', 'protoroles-annotator-39', 'protoroles-annotator-4', 'protoroles-annotator-40', 'protoroles-annotator-42', 'protoroles-annotator-43', 'protoroles-annotator-44', 'protoroles-annotator-45', 'protoroles-annotator-5', 'protoroles-annotator-6', 'protoroles-annotator-7', 'protoroles-annotator-8', 'protoroles-annotator-9']}, 'instigation': {'value': {'datatype': 'int', 'categories': [0, 1, 2, 3, 4], 'ordered': True}, 'confidence': {'datatype': 'int', 'categories': [0, 1], 'ordered': False}, 'annotators': ['protoroles-annotator-0', 'protoroles-annotator-1', 'protoroles-annotator-10', 'protoroles-annotator-11', 'protoroles-annotator-12', 'protoroles-annotator-13', 'protoroles-annotator-14', 'protoroles-annotator-15', 'protoroles-annotator-16', 'protoroles-annotator-17', 'protoroles-annotator-18', 'protoroles-annotator-19', 'protoroles-annotator-2', 'protoroles-annotator-20', 'protoroles-annotator-21', 'protoroles-annotator-22', 'protoroles-annotator-23', 'protoroles-annotator-24', 'protoroles-annotator-25', 'protoroles-annotator-26', 'protoroles-annotator-27', 'protoroles-annotator-28', 'protoroles-annotator-29', 'protoroles-annotator-3', 'protoroles-annotator-30', 'protoroles-annotator-31', 'protoroles-annotator-32', 'protoroles-annotator-33', 'protoroles-annotator-34', 'protoroles-annotator-35', 'protoroles-annotator-36', 'protoroles-annotator-37', 'protoroles-annotator-38', 'protoroles-annotator-39', 'protoroles-annotator-4', 'protoroles-annotator-40', 'protoroles-annotator-42', 'protoroles-annotator-43', 'protoroles-annotator-44', 'protoroles-annotator-45', 'protoroles-annotator-5', 'protoroles-annotator-6', 'protoroles-annotator-7', 'protoroles-annotator-8', 'protoroles-annotator-9']}, 'location': {'value': {'datatype': 'int', 'categories': [0, 1, 2, 3, 4], 'ordered': True}, 'confidence': {'datatype': 'int', 'categories': [0, 1], 'ordered': False}, 'annotators': ['protoroles-annotator-1', 'protoroles-annotator-10', 'protoroles-annotator-11', 'protoroles-annotator-13', 'protoroles-annotator-14', 'protoroles-annotator-16', 'protoroles-annotator-19', 'protoroles-annotator-20', 'protoroles-annotator-26', 'protoroles-annotator-29', 'protoroles-annotator-3', 'protoroles-annotator-34', 'protoroles-annotator-35', 'protoroles-annotator-38', 'protoroles-annotator-39', 'protoroles-annotator-4', 'protoroles-annotator-41', 'protoroles-annotator-42', 'protoroles-annotator-43', 'protoroles-annotator-6', 'protoroles-annotator-9']}, 'manner': {'value': {'datatype': 'int', 'categories': [0, 1, 2, 3, 4], 'ordered': True}, 'confidence': {'datatype': 'int', 'categories': [0, 1], 'ordered': False}, 'annotators': ['protoroles-annotator-1', 'protoroles-annotator-10', 'protoroles-annotator-11', 'protoroles-annotator-13', 'protoroles-annotator-14', 'protoroles-annotator-16', 'protoroles-annotator-19', 'protoroles-annotator-20', 'protoroles-annotator-26', 'protoroles-annotator-29', 'protoroles-annotator-3', 'protoroles-annotator-34', 'protoroles-annotator-35', 'protoroles-annotator-38', 'protoroles-annotator-39', 'protoroles-annotator-4', 'protoroles-annotator-41', 'protoroles-annotator-42', 'protoroles-annotator-43', 'protoroles-annotator-6', 'protoroles-annotator-9']}, 'partitive': {'value': {'datatype': 'int', 'categories': [0, 1, 2, 3, 4], 'ordered': True}, 'confidence': {'datatype': 'int', 'categories': [0, 1], 'ordered': False}, 'annotators': ['protoroles-annotator-0', 'protoroles-annotator-1', 'protoroles-annotator-10', 'protoroles-annotator-11', 'protoroles-annotator-12', 'protoroles-annotator-13', 'protoroles-annotator-14', 'protoroles-annotator-15', 'protoroles-annotator-16', 'protoroles-annotator-17', 'protoroles-annotator-18', 'protoroles-annotator-19', 'protoroles-annotator-2', 'protoroles-annotator-20', 'protoroles-annotator-21', 'protoroles-annotator-22', 'protoroles-annotator-23', 'protoroles-annotator-24', 'protoroles-annotator-25', 'protoroles-annotator-26', 'protoroles-annotator-27', 'protoroles-annotator-28', 'protoroles-annotator-29', 'protoroles-annotator-3', 'protoroles-annotator-30', 'protoroles-annotator-31', 'protoroles-annotator-32', 'protoroles-annotator-33', 'protoroles-annotator-34', 'protoroles-annotator-35', 'protoroles-annotator-36', 'protoroles-annotator-37', 'protoroles-annotator-38', 'protoroles-annotator-39', 'protoroles-annotator-4', 'protoroles-annotator-40', 'protoroles-annotator-42', 'protoroles-annotator-43', 'protoroles-annotator-44', 'protoroles-annotator-45', 'protoroles-annotator-5', 'protoroles-annotator-6', 'protoroles-annotator-7', 'protoroles-annotator-8', 'protoroles-annotator-9']}, 'purpose': {'value': {'datatype': 'int', 'categories': [0, 1, 2, 3, 4], 'ordered': True}, 'confidence': {'datatype': 'int', 'categories': [0, 1], 'ordered': False}, 'annotators': ['protoroles-annotator-1', 'protoroles-annotator-10', 'protoroles-annotator-11', 'protoroles-annotator-13', 'protoroles-annotator-14', 'protoroles-annotator-16', 'protoroles-annotator-19', 'protoroles-annotator-20', 'protoroles-annotator-26', 'protoroles-annotator-29', 'protoroles-annotator-3', 'protoroles-annotator-34', 'protoroles-annotator-35', 'protoroles-annotator-38', 'protoroles-annotator-39', 'protoroles-annotator-4', 'protoroles-annotator-41', 'protoroles-annotator-42', 'protoroles-annotator-43', 'protoroles-annotator-6', 'protoroles-annotator-9']}, 'sentient': {'value': {'datatype': 'int', 'categories': [0, 1, 2, 3, 4], 'ordered': True}, 'confidence': {'datatype': 'int', 'categories': [0, 1], 'ordered': False}, 'annotators': ['protoroles-annotator-0', 'protoroles-annotator-1', 'protoroles-annotator-10', 'protoroles-annotator-11', 'protoroles-annotator-12', 'protoroles-annotator-13', 'protoroles-annotator-14', 'protoroles-annotator-15', 'protoroles-annotator-16', 'protoroles-annotator-17', 'protoroles-annotator-18', 'protoroles-annotator-19', 'protoroles-annotator-2', 'protoroles-annotator-20', 'protoroles-annotator-21', 'protoroles-annotator-22', 'protoroles-annotator-23', 'protoroles-annotator-24', 'protoroles-annotator-25', 'protoroles-annotator-26', 'protoroles-annotator-27', 'protoroles-annotator-28', 'protoroles-annotator-29', 'protoroles-annotator-3', 'protoroles-annotator-30', 'protoroles-annotator-31', 'protoroles-annotator-32', 'protoroles-annotator-33', 'protoroles-annotator-34', 'protoroles-annotator-35', 'protoroles-annotator-36', 'protoroles-annotator-37', 'protoroles-annotator-38', 'protoroles-annotator-39', 'protoroles-annotator-4', 'protoroles-annotator-40', 'protoroles-annotator-42', 'protoroles-annotator-43', 'protoroles-annotator-44', 'protoroles-annotator-45', 'protoroles-annotator-5', 'protoroles-annotator-6', 'protoroles-annotator-7', 'protoroles-annotator-8', 'protoroles-annotator-9']}, 'time': {'value': {'datatype': 'int', 'categories': [0, 1, 2, 3, 4], 'ordered': True}, 'confidence': {'datatype': 'int', 'categories': [0, 1], 'ordered': False}, 'annotators': ['protoroles-annotator-1', 'protoroles-annotator-10', 'protoroles-annotator-11', 'protoroles-annotator-13', 'protoroles-annotator-14', 'protoroles-annotator-16', 'protoroles-annotator-19', 'protoroles-annotator-20', 'protoroles-annotator-26', 'protoroles-annotator-29', 'protoroles-annotator-3', 'protoroles-annotator-34', 'protoroles-annotator-35', 'protoroles-annotator-38', 'protoroles-annotator-39', 'protoroles-annotator-4', 'protoroles-annotator-41', 'protoroles-annotator-42', 'protoroles-annotator-43', 'protoroles-annotator-6', 'protoroles-annotator-9']}, 'volition': {'value': {'datatype': 'int', 'categories': [0, 1, 2, 3, 4], 'ordered': True}, 'confidence': {'datatype': 'int', 'categories': [0, 1], 'ordered': False}, 'annotators': ['protoroles-annotator-0', 'protoroles-annotator-1', 'protoroles-annotator-10', 'protoroles-annotator-11', 'protoroles-annotator-12', 'protoroles-annotator-13', 'protoroles-annotator-14', 'protoroles-annotator-15', 'protoroles-annotator-16', 'protoroles-annotator-17', 'protoroles-annotator-18', 'protoroles-annotator-19', 'protoroles-annotator-2', 'protoroles-annotator-20', 'protoroles-annotator-21', 'protoroles-annotator-22', 'protoroles-annotator-23', 'protoroles-annotator-24', 'protoroles-annotator-25', 'protoroles-annotator-26', 'protoroles-annotator-27', 'protoroles-annotator-28', 'protoroles-annotator-29', 'protoroles-annotator-3', 'protoroles-annotator-30', 'protoroles-annotator-31', 'protoroles-annotator-32', 'protoroles-annotator-33', 'protoroles-annotator-34', 'protoroles-annotator-35', 'protoroles-annotator-36', 'protoroles-annotator-37', 'protoroles-annotator-38', 'protoroles-annotator-39', 'protoroles-annotator-4', 'protoroles-annotator-40', 'protoroles-annotator-42', 'protoroles-annotator-43', 'protoroles-annotator-44', 'protoroles-annotator-45', 'protoroles-annotator-5', 'protoroles-annotator-6', 'protoroles-annotator-7', 'protoroles-annotator-8', 'protoroles-annotator-9']}, 'was_for_benefit': {'value': {'datatype': 'int', 'categories': [0, 1, 2, 3, 4], 'ordered': True}, 'confidence': {'datatype': 'int', 'categories': [0, 1], 'ordered': False}, 'annotators': ['protoroles-annotator-0', 'protoroles-annotator-1', 'protoroles-annotator-10', 'protoroles-annotator-11', 'protoroles-annotator-12', 'protoroles-annotator-13', 'protoroles-annotator-14', 'protoroles-annotator-15', 'protoroles-annotator-16', 'protoroles-annotator-17', 'protoroles-annotator-18', 'protoroles-annotator-19', 'protoroles-annotator-2', 'protoroles-annotator-20', 'protoroles-annotator-21', 'protoroles-annotator-22', 'protoroles-annotator-23', 'protoroles-annotator-24', 'protoroles-annotator-25', 'protoroles-annotator-26', 'protoroles-annotator-27', 'protoroles-annotator-28', 'protoroles-annotator-29', 'protoroles-annotator-3', 'protoroles-annotator-30', 'protoroles-annotator-31', 'protoroles-annotator-32', 'protoroles-annotator-33', 'protoroles-annotator-34', 'protoroles-annotator-35', 'protoroles-annotator-36', 'protoroles-annotator-37', 'protoroles-annotator-38', 'protoroles-annotator-39', 'protoroles-annotator-4', 'protoroles-annotator-40', 'protoroles-annotator-42', 'protoroles-annotator-43', 'protoroles-annotator-44', 'protoroles-annotator-45', 'protoroles-annotator-5', 'protoroles-annotator-6', 'protoroles-annotator-7', 'protoroles-annotator-8', 'protoroles-annotator-9']}, 'was_used': {'value': {'datatype': 'int', 'categories': [0, 1, 2, 3, 4], 'ordered': True}, 'confidence': {'datatype': 'int', 'categories': [0, 1], 'ordered': False}, 'annotators': ['protoroles-annotator-0', 'protoroles-annotator-1', 'protoroles-annotator-10', 'protoroles-annotator-11', 'protoroles-annotator-12', 'protoroles-annotator-13', 'protoroles-annotator-14', 'protoroles-annotator-15', 'protoroles-annotator-16', 'protoroles-annotator-17', 'protoroles-annotator-18', 'protoroles-annotator-19', 'protoroles-annotator-2', 'protoroles-annotator-20', 'protoroles-annotator-21', 'protoroles-annotator-22', 'protoroles-annotator-23', 'protoroles-annotator-24', 'protoroles-annotator-25', 'protoroles-annotator-26', 'protoroles-annotator-27', 'protoroles-annotator-28', 'protoroles-annotator-29', 'protoroles-annotator-3', 'protoroles-annotator-30', 'protoroles-annotator-31', 'protoroles-annotator-32', 'protoroles-annotator-33', 'protoroles-annotator-34', 'protoroles-annotator-35', 'protoroles-annotator-36', 'protoroles-annotator-37', 'protoroles-annotator-38', 'protoroles-annotator-39', 'protoroles-annotator-4', 'protoroles-annotator-40', 'protoroles-annotator-42', 'protoroles-annotator-43', 'protoroles-annotator-44', 'protoroles-annotator-45', 'protoroles-annotator-5', 'protoroles-annotator-6', 'protoroles-annotator-7', 'protoroles-annotator-8', 'protoroles-annotator-9']}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"./data/protoroles.json\") as j:\n",
    "    data = json.load(j)\n",
    "    print(data['metadata']['protoroles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbaseconda799f00ec29b4497e893025422d5f5a3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
