{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9I9rz0pTamX"
   },
   "source": [
    "# Edge-Probing Fine-tuning Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EiowR0WNTd1C"
   },
   "source": [
    "In this notebook, we will:\n",
    "\n",
    "* Train a RoBERTa base model on Edge-Probing (Semeval) and evaluate its performance\n",
    "* Because the Edge-Probing data is not publicly available, we will simulate the run with a single example. This will serve as a guide for users who have access to the task data, or similarly formatted data.\n",
    "* **The encoder is not frozen for training runs in this notebook.**\n",
    "\n",
    "The code shown in this notebook will work, but the results will not be representative of the task!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rQKSAhYzVIlv"
   },
   "source": [
    "## `jiant` Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ibmMT7CXv1_P"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import jiant.proj.main.tokenize_and_cache as tokenize_and_cache\n",
    "import jiant.proj.main.export_model as export_model\n",
    "import jiant.proj.main.scripts.configurator as configurator\n",
    "import jiant.proj.main.runscript as main_runscript\n",
    "import jiant.utils.python.io as py_io\n",
    "import jiant.utils.display as display\n",
    "\n",
    "from rich.progress import track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8518\n",
      "# good:  5657\n",
      "# wrong:  2861\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "task_name = \"hellaswag\"\n",
    "task_split=\"val\"\n",
    "binarynli_classes = [\"entailed\", \"not-entailed\"]\n",
    "commnli_classes = [\"entailment\", \"contradiction\", \"neutral\"]\n",
    "acc_report = {}\n",
    "val_data = py_io.read_jsonl(\n",
    "    f\"/content/tasks/curriculum/{task_name}/{task_split}.jsonl\")\n",
    "print(len(val_data))\n",
    "preds = torch.load(f\"./runs/{task_name}/anli-mix-roberta/1000-shot/val_preds.p\")[task_name]['preds']\n",
    "\n",
    "labels = {}\n",
    "good_predictions = []\n",
    "wrong_predictions = []\n",
    "\n",
    "for i, pred in enumerate(preds):\n",
    "    label = val_data[i]['gold_label']\n",
    "    if pred == binarynli_classes.index(label):\n",
    "        good_predictions.append(val_data[i])\n",
    "    else:\n",
    "        wrong_predictions.append(val_data[i])\n",
    "\n",
    "print(\"# good: \", len(good_predictions))\n",
    "print(\"# wrong: \", len(wrong_predictions))\n",
    "\n",
    "val_data = wrong_predictions\n",
    "good_selected, _ = get_k_shot_data_multi(good_predictions, k=3000)\n",
    "val_data += good_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6719\n",
      "1604\n"
     ]
    }
   ],
   "source": [
    "import jiant.utils.python.io as py_io\n",
    "\n",
    "train_data_raw = py_io.read_jsonl(\"./curriculum/control/train.jsonl.txt\")\n",
    "val_data_raw = py_io.read_jsonl(\"./curriculum/control/test.jsonl.txt\")\n",
    "val_data_raw += py_io.read_jsonl(\"./curriculum/control/dev.jsonl.txt\")\n",
    "\n",
    "print(len(train_data_raw))\n",
    "print(len(val_data_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {'e':'entailment', 'c':'contradiction', 'n':\"neutral\"}\n",
    "\n",
    "for data in train_data_raw:\n",
    "  label = data.pop('label')\n",
    "  data['gold_label'] = label_map[label]\n",
    "\n",
    "for data in val_data_raw:\n",
    "  label = data.pop('label')\n",
    "  data['gold_label'] = label_map[label]\n",
    "\n",
    "train_data = train_data_raw\n",
    "val_data = val_data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "train_data = []\n",
    "val_data = []\n",
    "\n",
    "label_map = {'A':0, 'B':1, 'C':2, 'D':3, 'E':4}\n",
    "\n",
    "idx = 0\n",
    "for data in train_data_raw:\n",
    "  questions = data['questions']\n",
    "  passage = data['passage']\n",
    "  for question in questions:\n",
    "    premise = f\"{passage} {question['question']}\"\n",
    "    label = label_map[question['answer']]\n",
    "    options = question['options']\n",
    "    hypothesis = options.pop(label)\n",
    "    random_hypo = random.choice(options)\n",
    "    example = {\n",
    "      'idx': idx,\n",
    "      'premise': premise,\n",
    "      'hypothesis': hypothesis,\n",
    "      'gold_label': \"entailed\"\n",
    "    }\n",
    "    idx += 1\n",
    "    example_n = {\n",
    "      'idx': idx,\n",
    "      'premise': premise,\n",
    "      'hypothesis': random_hypo,\n",
    "      'gold_label': \"not-entailed\"\n",
    "    }\n",
    "    idx += 1\n",
    "    train_data.append(example)\n",
    "    train_data.append(example_n)\n",
    "\n",
    "idx = 0\n",
    "for data in val_data_raw:\n",
    "  questions = data['questions']\n",
    "  passage = data['passage']\n",
    "  for question in questions:\n",
    "    premise = f\"{passage} {question['question']}\"\n",
    "    label = label_map[question['answer']]\n",
    "    options = question['options']\n",
    "    hypothesis = options.pop(label)\n",
    "    random_hypo = random.choice(options)\n",
    "    example = {\n",
    "      'idx': idx,\n",
    "      'premise': premise,\n",
    "      'hypothesis': hypothesis,\n",
    "      'gold_label': \"entailed\"\n",
    "    }\n",
    "    idx += 1\n",
    "    example_n = {\n",
    "      'idx': idx,\n",
    "      'premise': premise,\n",
    "      'hypothesis': random_hypo,\n",
    "      'gold_label': \"not-entailed\"\n",
    "    }\n",
    "    idx += 1\n",
    "    val_data.append(example)\n",
    "    val_data.append(example_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4248\n"
     ]
    }
   ],
   "source": [
    "train_data_raw = [x.strip() for x in open(\"./curriculum/temporal/tracie_test.txt\").readlines()]\n",
    "val_data_raw = [x.strip() for x in open(\"./curriculum/temporal/tracie_train.txt\").readlines()]\n",
    "\n",
    "print(len(train_data_raw))\n",
    "\n",
    "train_data = []\n",
    "val_data = []\n",
    "label_map = {\"positive\": \"entailed\", \"negative\": \"not-entailed\"}\n",
    "\n",
    "for i, l in enumerate(train_data_raw):\n",
    "    if \"story:\" in l.split(\"\\t\")[0]:\n",
    "        story = l.split(\"\\t\")[0].split(\"story:\")[1]\n",
    "    else:\n",
    "        story = \"no story\"\n",
    "    if \"event:\" in l.split(\"\\t\")[0].split(\"story:\")[0]:\n",
    "        event = l.split(\"\\t\")[0].split(\"story:\")[0].split(\"event:\")[1]\n",
    "    else:\n",
    "        event = \"no event happend\"\n",
    "    label = l.split(\"\\t\")[1].split()[1]\n",
    "    example = {\n",
    "        \"idx\": i, \"premise\": story, \"hypothesis\": event, \"gold_label\": label_map[label]\n",
    "    }\n",
    "    train_data.append(example)\n",
    "\n",
    "for i, l in enumerate(val_data_raw):\n",
    "    if \"story:\" in l.split(\"\\t\")[0]:\n",
    "        story = l.split(\"\\t\")[0].split(\"story:\")[1]\n",
    "    else:\n",
    "        story = \"no story\"\n",
    "    if \"event:\" in l.split(\"\\t\")[0].split(\"story:\")[0]:\n",
    "        event = l.split(\"\\t\")[0].split(\"story:\")[0].split(\"event:\")[1]\n",
    "    else:\n",
    "        event = \"no event happend\"\n",
    "    label = l.split(\"\\t\")[1].split()[1]\n",
    "    example = {\n",
    "        \"idx\": i, \"premise\": story, \"hypothesis\": event, \"gold_label\": label_map[label]\n",
    "    }\n",
    "    val_data.append(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "train_data = []\n",
    "val_data = []\n",
    "\n",
    "idx = 0\n",
    "for data in train_data_raw:\n",
    "  premise = data['ctx']\n",
    "  label = int(data['label'])\n",
    "  endings = data['endings']\n",
    "  hypothesis = endings.pop(label)\n",
    "  random_hypo = random.choice(endings)\n",
    "  example = {\n",
    "    'idx': idx,\n",
    "    'premise': premise,\n",
    "    'hypothesis': hypothesis,\n",
    "    'gold_label': \"entailed\"\n",
    "  }\n",
    "  idx += 1\n",
    "  example_n = {\n",
    "    'idx': idx,\n",
    "    'premise': premise,\n",
    "    'hypothesis': random_hypo,\n",
    "    'gold_label': \"not-entailed\"\n",
    "  }\n",
    "  idx += 1\n",
    "  train_data.append(example)\n",
    "  train_data.append(example_n)\n",
    "\n",
    "idx = 0\n",
    "for data in val_data_raw:\n",
    "  premise = data['ctx']\n",
    "  label = int(data['label'])\n",
    "  endings = data['endings']\n",
    "  hypothesis = endings.pop(label)\n",
    "  random_hypo = random.choice(endings)\n",
    "  example = {\n",
    "    'idx': idx,\n",
    "    'premise': premise,\n",
    "    'hypothesis': hypothesis,\n",
    "    'gold_label': \"entailed\"\n",
    "  }\n",
    "  idx += 1\n",
    "  example_n = {\n",
    "    'idx': idx,\n",
    "    'premise': premise,\n",
    "    'hypothesis': random_hypo,\n",
    "    'gold_label': \"not-entailed\"\n",
    "  }\n",
    "  idx += 1\n",
    "  val_data.append(example)\n",
    "  val_data.append(example_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_data_rest = get_k_shot_data_multi(train_data, k=10000)\n",
    "val_data, val_data_rest = get_k_shot_data_multi(val_data, k=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"control\"\n",
    "\n",
    "os.makedirs(\"/content/tasks/configs/\", exist_ok=True)\n",
    "os.makedirs(f\"/content/tasks/curriculum/{task_name}\", exist_ok=True)\n",
    "py_io.write_jsonl(\n",
    "    data=train_data,\n",
    "    path=f\"/content/tasks/curriculum/{task_name}/train.jsonl\",\n",
    ")\n",
    "py_io.write_jsonl(\n",
    "    data=val_data,\n",
    "    path=f\"/content/tasks/curriculum/{task_name}/val.jsonl\",\n",
    ")\n",
    "py_io.write_json({\n",
    "  \"task\": f\"{task_name}\",\n",
    "  \"paths\": {\n",
    "    \"train\": f\"/content/tasks/curriculum/{task_name}/train.jsonl\",\n",
    "    \"val\": f\"/content/tasks/curriculum/{task_name}/val.jsonl\",\n",
    "  },\n",
    "  \"name\": f\"{task_name}\"\n",
    "}, f\"/content/tasks/configs/{task_name}_config.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ihjR1g_1phl"
   },
   "source": [
    "## Creating sample Edge-Probing data.\n",
    "\n",
    "Because the Edge-Probing data is not publicly available, we will simulate the run with a single example. We will write 1000 copies for the training set and 100 copies for the validation set. We will also write the corresponding task config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_k_shot_data(datalist, seed=42, k_p=6000, k_n=6000, balanced=False):\n",
    "    # Set random seed\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Shuffle the training set\n",
    "    train_lines = datalist\n",
    "    np.random.shuffle(train_lines)\n",
    "\n",
    "    # Get label list for balanced sampling\n",
    "    label_list = {}\n",
    "    for line in train_lines:\n",
    "        label = line['gold_label']\n",
    "        if label not in label_list:\n",
    "            label_list[label] = [line]\n",
    "        else:\n",
    "            label_list[label].append(line)\n",
    "\n",
    "    new_train = []\n",
    "    #for label in label_list:\n",
    "    k = k_p\n",
    "    for line in label_list[\"entailed\"][:k]:\n",
    "        new_train.append(line)\n",
    "    if not balanced:\n",
    "        k = k_n\n",
    "    for line in label_list[\"not-entailed\"][:k]:\n",
    "        new_train.append(line)\n",
    "    return new_train\n",
    "\n",
    "def get_k_shot_data_multi(train_lines, seed=42, k=320):\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(train_lines)\n",
    "    label_list = {}\n",
    "    for line in train_lines:\n",
    "        label = line['gold_label']\n",
    "        if label not in label_list:\n",
    "            label_list[label] = [line]\n",
    "        else:\n",
    "            label_list[label].append(line)\n",
    "    new_train = []\n",
    "    new_train_rest = []\n",
    "    for label in label_list:\n",
    "        new_train += label_list[label][:k]\n",
    "        new_train_rest += label_list[label][k:]\n",
    "    return new_train, new_train_rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexical_tasks = [\n",
    "    \"lexical\",\n",
    "    \"transitive\",\n",
    "    \"hypernymy\",\n",
    "    \"hyponymy\",\n",
    "    \"ner\"\n",
    "]\n",
    "\n",
    "syntactic_tasks = [\n",
    "    \"verbnet\",\n",
    "    \"verbcorner\",\n",
    "    \"syntactic_alternation\",\n",
    "    \"syntactic_variation\",\n",
    "]\n",
    "\n",
    "logical_tasks = [\n",
    "    \"boolean\",\n",
    "    \"comparative\",\n",
    "    \"conditional\",\n",
    "    \"counting\",\n",
    "    \"negation\",\n",
    "    \"quantifier\",\n",
    "    \"monotonicity_infer\",\n",
    "    \"syllogism\"\n",
    "]\n",
    "\n",
    "semantic_tasks = [\n",
    "    \"sentiment\",\n",
    "    \"kg_relations\",\n",
    "    \"puns\",\n",
    "    \"coreference\",\n",
    "    \"context_align\",\n",
    "    \"sprl\"\n",
    "]\n",
    "\n",
    "knowledge_tasks = [\n",
    "    \"entailment_tree\",\n",
    "    \"proof_writer\"\n",
    "]\n",
    "\n",
    "commonsense_tasks = [\n",
    "    \"socialqa\",\n",
    "    \"physicalqa\",\n",
    "    \"atomic\",\n",
    "    \"social_chem\"\n",
    "]\n",
    "\n",
    "comprehension_tasks = [\n",
    "    \"logiqa\",\n",
    "    \"cosmoqa\",\n",
    "    \"ester\",\n",
    "    \"drop\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for sentiment . . .\n",
      "600\n",
      "Processing data for kg_relations . . .\n",
      "761\n",
      "Processing data for puns . . .\n",
      "1756\n",
      "Processing data for coreference . . .\n",
      "5799\n",
      "Processing data for context_align . . .\n",
      "7288\n",
      "Processing data for sprl . . .\n",
      "8500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24704"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = []\n",
    "val_data = []\n",
    "\n",
    "all_tasks = [\"lexical_inference\", \"syntactic_inference\", \"logical_inference\", \"semantic_inference\", \"commonsense_inference\", \"knowledge_inference\"]\n",
    "fundamental_tasks = [\n",
    "  \"hypernymy\", \"hyponymy\", \"syntactic_alternation\", \"syntactic_variation\",\n",
    "  \"boolean\", \"comparative\", \"conditional\", \"counting\", \"negation\", \"quantifier\",\"syllogism\", \n",
    "  \"sentiment\",\"kg_relations\",\"puns\",\"coreference\",\"sprl\"]\n",
    "\n",
    "complex_tasks = [\"context_align\", \"entailment_tree\",\n",
    "                 \"monotonicity_infer\", \"socialqa\",\n",
    "                 \"physicalqa\",\"atomic\",\"social_chem\",\n",
    "                 \"logiqa\",\"cosmoqa\",\"ester\",\"spatial\",\"temporal\", \"counterfactual\"]\n",
    "\n",
    "all_tasks = fundamental_tasks + complex_tasks\n",
    "\n",
    "for task in semantic_tasks:\n",
    "  train_data_raw = py_io.read_jsonl(f\"/content/tasks/curriculum/{task}/train.jsonl\")\n",
    "  val_data_raw = py_io.read_jsonl(f\"/content/tasks/curriculum/{task}/val.jsonl\")\n",
    "\n",
    "  print(f\"Processing data for {task} . . .\")\n",
    "  print(len(val_data_raw))\n",
    "\n",
    "  if task != \"monotonicity_hard\":\n",
    "    for train in train_data_raw:\n",
    "      label = train[\"gold_label\"]\n",
    "      if label in [\"contradiction\", \"neutral\"]:\n",
    "        label = \"not-entailed\"\n",
    "      elif label == \"entailment\":\n",
    "        label = \"entailed\"\n",
    "      example = {\n",
    "        \"premise\": train[\"premise\"],\n",
    "        \"hypothesis\": train[\"hypothesis\"],\n",
    "        \"task\": task,\n",
    "        \"gold_label\": label,\n",
    "      }\n",
    "      train_data.append(example)\n",
    "\n",
    "  for val in val_data_raw:\n",
    "    label = val[\"gold_label\"]\n",
    "    if label in [\"contradiction\", \"neutral\"]:\n",
    "      label = \"not-entailed\"\n",
    "    elif label == \"entailment\":\n",
    "      label = \"entailed\"\n",
    "    example = {\n",
    "      \"premise\": val[\"premise\"],\n",
    "      \"hypothesis\": val[\"hypothesis\"],\n",
    "      \"task\": task,\n",
    "      \"gold_label\": label,\n",
    "    }\n",
    "    val_data.append(example)\n",
    "\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(train_data)\n",
    "np.random.shuffle(val_data)\n",
    "len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in val_data:\n",
    "  if 'sentence1' in data:\n",
    "    data['premise'] = data.pop('sentence1')\n",
    "  if 'sentence2' in data:\n",
    "    data['hypothesis'] = data.pop('sentence2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"lexical\"\n",
    "\n",
    "os.makedirs(\"/content/tasks/configs/\", exist_ok=True)\n",
    "os.makedirs(f\"/content/tasks/curriculum/{task_name}\", exist_ok=True)\n",
    "py_io.write_jsonl(\n",
    "    data=train_data,\n",
    "    path=f\"/content/tasks/curriculum/{task_name}/train.jsonl\",\n",
    ")\n",
    "py_io.write_jsonl(\n",
    "    data=val_data,\n",
    "    path=f\"/content/tasks/curriculum/{task_name}/val.jsonl\",\n",
    ")\n",
    "py_io.write_json({\n",
    "  \"task\": f\"{task_name}\",\n",
    "  \"paths\": {\n",
    "    \"train\": f\"/content/tasks/curriculum/{task_name}/train.jsonl\",\n",
    "    \"val\": f\"/content/tasks/curriculum/{task_name}/val.jsonl\",\n",
    "  },\n",
    "  \"name\": f\"{task_name}\"\n",
    "}, f\"/content/tasks/configs/{task_name}_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_med = py_io.read_json(\"./curriculum/MED.json\")\n",
    "\n",
    "val_data = []\n",
    "for line in val_data_med:\n",
    "  label = line['gold_label']\n",
    "  if label == \"entailment\":\n",
    "    label = \"entailed\"\n",
    "  else:\n",
    "    label = \"not-entailed\"\n",
    "  example = {\n",
    "    'premise': line['sentence1'],\n",
    "    'hypothesis': line['sentence2'],\n",
    "    'gold_label': label\n",
    "  }\n",
    "  val_data.append(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6382"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data_seg = py_io.read_jsonl(\"./curriculum/Logical/monotonicity_hard/test/test.json\")\n",
    "for line in val_data_seg:\n",
    "  label = line['gold_label']\n",
    "  if label == \"entailment\":\n",
    "    label = \"entailed\"\n",
    "  else:\n",
    "    label = \"not-entailed\"\n",
    "  example = {\n",
    "    'premise': line['sentence1'],\n",
    "    'hypothesis': line['sentence2'],\n",
    "    'gold_label': label\n",
    "  }\n",
    "  val_data.append(example)\n",
    "len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35308\n",
      "25494\n"
     ]
    }
   ],
   "source": [
    "import jiant.utils.python.io as py_io\n",
    "\n",
    "train_data_raw = py_io.read_jsonl(\"/content/tasks/curriculum/curriculum/train.jsonl\")\n",
    "val_data_raw = py_io.read_jsonl(\"/content/tasks/curriculum/curriculum/val.jsonl\")\n",
    "\n",
    "print(len(train_data_raw))\n",
    "print(len(val_data_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['label', 'idx', 'text_a', 'text_b'])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_raw[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1506"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_by_label = {}\n",
    "for data in train_data_raw:\n",
    "  if data['label'] in data_by_label:\n",
    "    data_by_label[data['label']].append(data)\n",
    "  else:\n",
    "    data_by_label[data['label']] = [data]\n",
    "\n",
    "len(data_by_label['entailed'])\n",
    "len(data_by_label['not-entailed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "entailed = data_by_label['entailed'][1494:]\n",
    "not_entailed = data_by_label['not-entailed'][1306:]\n",
    "train_data_raw = data_by_label['entailed'][:1494] + data_by_label['not-entailed'][:1306]\n",
    "val_data_raw += entailed + not_entailed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "val_data = []\n",
    "\n",
    "classes = ['not-entailed', 'entailed']\n",
    "\n",
    "for data in train_data_raw:\n",
    "  premise = data.pop('text_a')\n",
    "  hypothesis = data.pop('text_b')\n",
    "  label = data.pop('label')\n",
    "  data['premise'] = premise\n",
    "  data['hypothesis'] = hypothesis\n",
    "  data['gold_label'] = classes[int(label)]\n",
    "  train_data.append(data)\n",
    "\n",
    "for data in val_data_raw:\n",
    "  premise = data.pop('text_a')\n",
    "  hypothesis = data.pop('text_b')\n",
    "  label = data.pop('label')\n",
    "  data['premise'] = premise\n",
    "  data['hypothesis'] = hypothesis\n",
    "  data['gold_label'] = classes[int(label)]\n",
    "  val_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "val_data = []\n",
    "\n",
    "entail = True\n",
    "\n",
    "for i, line in enumerate(train_data_raw):\n",
    "  context = line['context']\n",
    "  question = line['question']\n",
    "  context += question\n",
    "  answer = ' '.join(line['answer_texts'])\n",
    "  hypothesis = f\"\\\"{answer} \\\" .\"\n",
    "\n",
    "  false_answer = context\n",
    "  for txt in line['answer_texts']:\n",
    "    false_answer = false_answer.replace(txt, \"\")\n",
    "  flase_hypothesis = f\"\\\"{false_answer} \\\" .\"\n",
    "\n",
    "  example_ent = {\n",
    "    \"premise\": context,\n",
    "    \"hypothesis\": hypothesis,\n",
    "    \"gold_label\": \"entailed\"\n",
    "  }\n",
    "  exmaple_nent = {\n",
    "    \"premise\": context,\n",
    "    \"hypothesis\": flase_hypothesis,\n",
    "    \"gold_label\": \"not-entailed\"\n",
    "  }\n",
    "\n",
    "  train_data.append(example_ent)\n",
    "  train_data.append(exmaple_nent)\n",
    "  entail = not entail\n",
    "\n",
    "for i, line in enumerate(val_data_raw):\n",
    "  context = line['context']\n",
    "  question = line['question']\n",
    "  context += question\n",
    "  answer = ' '.join(line['answer_texts'])\n",
    "  hypothesis = f\"\\\"{answer} \\\" .\"\n",
    "\n",
    "  false_answer = context\n",
    "  for txt in line['answer_texts']:\n",
    "    false_answer = false_answer.replace(txt, \"\")\n",
    "  flase_hypothesis = f\"\\\"{false_answer} \\\" .\"\n",
    "\n",
    "  example_ent = {\n",
    "    \"premise\": context,\n",
    "    \"hypothesis\": hypothesis,\n",
    "    \"gold_label\": \"entailed\"\n",
    "  }\n",
    "  exmaple_nent = {\n",
    "    \"premise\": context,\n",
    "    \"hypothesis\": flase_hypothesis,\n",
    "    \"gold_label\": \"not-entailed\"\n",
    "  }\n",
    "\n",
    "  val_data.append(example_ent)\n",
    "  val_data.append(exmaple_nent)\n",
    "  entail = not entail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_plus, train_data_rest = get_k_shot_data_multi(train_data, k=500)\n",
    "val_data += val_data_plus\n",
    "train_data = train_data_rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"syntactic_variation\"\n",
    "\n",
    "os.makedirs(\"/content/tasks/configs/\", exist_ok=True)\n",
    "os.makedirs(f\"/content/tasks/curriculum/{task_name}\", exist_ok=True)\n",
    "py_io.write_jsonl(\n",
    "    data=train_data,\n",
    "    path=f\"/content/tasks/curriculum/{task_name}/train.jsonl\",\n",
    ")\n",
    "py_io.write_jsonl(\n",
    "    data=val_data,\n",
    "    path=f\"/content/tasks/curriculum/{task_name}/val.jsonl\",\n",
    ")\n",
    "py_io.write_json({\n",
    "  \"task\": f\"{task_name}\",\n",
    "  \"paths\": {\n",
    "    \"train\": f\"/content/tasks/curriculum/{task_name}/train.jsonl\",\n",
    "    \"val\": f\"/content/tasks/curriculum/{task_name}/val.jsonl\",\n",
    "  },\n",
    "  \"name\": f\"{task_name}\"\n",
    "}, f\"/content/tasks/configs/{task_name}_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_shot_task_data(train_lines, k_shot=10):\n",
    "    task_list = {}\n",
    "    for line in train_lines:\n",
    "        task = line['task']\n",
    "        if task not in task_list:\n",
    "            task_list[task] = [line]\n",
    "        else:\n",
    "            task_list[task].append(line)\n",
    "    print(len(task_list))\n",
    "    new_train = []\n",
    "    for task in task_list:\n",
    "        new_train_task = get_k_shot_data_multi(task_list[task], k=k_shot)\n",
    "        new_train += new_train_task\n",
    "    return new_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for line in train_data_raw:\n",
    "  label = line['UpdateType']\n",
    "  if label == \"strengthener\":\n",
    "    gold = \"entailed\"\n",
    "  elif label == \"weakener\":\n",
    "    gold = \"not-entailed\"\n",
    "  example = {\n",
    "    'premise': f\"{line['Premise']} ; {line['Update']}\",\n",
    "    'hypothesis': line['Hypothesis'],\n",
    "    'gold_label': gold\n",
    "  }\n",
    "  train_data.append(example)\n",
    "\n",
    "val_data = []\n",
    "for line in val_data_raw:\n",
    "  label = line['UpdateType']\n",
    "  if label == \"strengthener\":\n",
    "    gold = \"entailed\"\n",
    "  elif label == \"weakener\":\n",
    "    gold = \"not-entailed\"\n",
    "  example = {\n",
    "    'premise': f\"{line['Premise']} ; {line['Update']}\",\n",
    "    'hypothesis': line['Hypothesis'],\n",
    "    'gold_label': gold\n",
    "  }\n",
    "  val_data.append(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for line in train_data_raw:\n",
    "  label = line['UpdateType']\n",
    "  if label == \"strengthener\":\n",
    "    gold = \"entailed\"\n",
    "  elif label == \"weakener\":\n",
    "    gold = \"not-entailed\"\n",
    "  example = {\n",
    "    'premise': f\"{line['SocialChemSituation']} ; {line['Update']}\",\n",
    "    'hypothesis': line['Hypothesis'],\n",
    "    'gold_label': gold\n",
    "  }\n",
    "  train_data.append(example)\n",
    "\n",
    "val_data = []\n",
    "for line in val_data_raw:\n",
    "  label = line['UpdateType']\n",
    "  if label == \"strengthener\":\n",
    "    gold = \"entailed\"\n",
    "  elif label == \"weakener\":\n",
    "    gold = \"not-entailed\"\n",
    "  example = {\n",
    "    'premise': f\"{line['SocialChemSituation']} ; {line['Update']}\",\n",
    "    'hypothesis': line['Hypothesis'],\n",
    "    'gold_label': gold\n",
    "  }\n",
    "  val_data.append(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for line in train_data_raw:\n",
    "  label = line['label']\n",
    "  if label == 1:\n",
    "    gold = \"entailed\"\n",
    "  else:\n",
    "    gold = \"not-entailed\"\n",
    "  example = {\n",
    "    'premise': line['text_a'],\n",
    "    'hypothesis': line['text_b'],\n",
    "    'gold_label': gold\n",
    "  }\n",
    "  train_data.append(example)\n",
    "\n",
    "val_data = []\n",
    "for line in val_data_raw:\n",
    "  label = line['label']\n",
    "  if label == 1:\n",
    "    gold = \"entailed\"\n",
    "  else:\n",
    "    gold = \"not-entailed\"\n",
    "  example = {\n",
    "    'premise': line['text_a'],\n",
    "    'hypothesis': line['text_b'],\n",
    "    'gold_label': gold\n",
    "  }\n",
    "  val_data.append(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(train_data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for line in train_data_raw:\n",
    "  try:\n",
    "    \"\"\"if type(line['hypothesis']) == \"list\":\n",
    "      if len(line['hypothesis']) > 1:\n",
    "        hypothesis = f\"{line['hypothesis'][0]} , {line['hypothesis'][1]}\"\n",
    "      else:\n",
    "        hypothesis = line['hypothesis'][0]\n",
    "    else:\n",
    "      hypothesis = line['hypothesis']\"\"\"\n",
    "    example = {\n",
    "      'premise': line['premise'].replace(\"\\n\", \"\"),\n",
    "      'hypothesis': line['hypothesis'].replace(\"[\", \"\").replace(\"]\", \"\"),\n",
    "      'gold_label': line['label']\n",
    "    }\n",
    "    train_data.append(example)\n",
    "  except:\n",
    "    print(line.keys())\n",
    "\n",
    "val_data = []\n",
    "for line in val_data_raw:\n",
    "  try:\n",
    "    \"\"\"if type(line['hypothesis']) != \"str\":\n",
    "      if len(line['hypothesis']) > 1:\n",
    "        hypothesis = f\"{line['hypothesis'][0]} , {line['hypothesis'][1]}\"\n",
    "      else:\n",
    "        hypothesis = line['hypothesis'][0]\n",
    "    else:\n",
    "      hypothesis = line['hypothesis']\"\"\"\n",
    "    example = {\n",
    "      'premise': line['premise'].replace(\"\\n\", \"\"),\n",
    "      'hypothesis': line['hypothesis'].replace(\"[\", \"\").replace(\"]\", \"\"),\n",
    "      'gold_label': line['label']\n",
    "    }\n",
    "    val_data.append(example)\n",
    "  except:\n",
    "    print(line.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DefinitionQA Convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_raw_easy = py_io.read_json(\"./curriculum/CoDA-clean-easy.json\", encoding=\"utf8\")\n",
    "val_data_raw_hard = py_io.read_json(\"./curriculum/CoDA-clean-hard.json\", encoding=\"utf8\")\n",
    "\n",
    "val_data_align = []\n",
    "\n",
    "for verb_set in val_data_raw_easy['n']:\n",
    "  candidates = verb_set['candidates']\n",
    "  for candidate in candidates:\n",
    "    word = candidate['words_in_contexts'][0]\n",
    "    premise = candidate['contexts'][0].replace(word, \"<mask>\")\n",
    "    definiton = candidate['definition']\n",
    "    hypothesis = f\"the proper context for <mask> here should be {definiton}\"\n",
    "    example = {\n",
    "      'premise': premise,\n",
    "      'hypothesis': hypothesis,\n",
    "      'gold_label': \"entailed\"\n",
    "    }\n",
    "    val_data_align.append(example)\n",
    "\n",
    "for verb_set in val_data_raw_hard['n']:\n",
    "  candidates = verb_set['candidates']\n",
    "  for candidate in candidates:\n",
    "    word = candidate['words_in_contexts'][0]\n",
    "    premise = candidate['contexts'][0].replace(word, \"<mask>\")\n",
    "    definiton = candidate['definition']\n",
    "    hypothesis = f\"the proper context for <mask> here should be {definiton}\"\n",
    "    example = {\n",
    "      'premise': premise,\n",
    "      'hypothesis': hypothesis,\n",
    "      'gold_label': \"entailed\"\n",
    "    }\n",
    "    val_data_align.append(example)\n",
    "\n",
    "\n",
    "len(val_data_align)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_defqa = py_io.read_jsonl(\"/content/tasks/curriculum/context_align_complete/train.jsonl\")\n",
    "val_data_defqa = py_io.read_jsonl(\"/content/tasks/curriculum/context_align_complete/val.jsonl\")\n",
    "\n",
    "train_data = get_k_shot_data(train_data_defqa)\n",
    "val_data_new = get_k_shot_data(val_data_defqa, k_p=500, k_n=3239)\n",
    "val_data = val_data_new + val_data_align\n",
    "\n",
    "count_labels(train_data)\n",
    "count_labels(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': {'stem': \"In the expression 'prismatic colors', the following is the best characterization of the word/phrase 'prismatic'\",\n",
       "  'choices': [{'label': 0, 'text': 'Unevenness; inequality of surface.'},\n",
       "   {'label': 1, 'text': 'Resembling, or pertaining to, a prism'},\n",
       "   {'label': 2,\n",
       "    'text': 'Separated or distributed by a prism; formed by a prism'},\n",
       "   {'label': 3, 'text': 'Made thick or thicker; thickened; inspissated.'},\n",
       "   {'label': 4, 'text': 'To imitate; to mimic; to personate.'}]},\n",
       " 'answerKey': 2,\n",
       " 'notes': {'gold_synset': 'prismatic.u.2',\n",
       "  'distractor_synsets': ['wave.u.11',\n",
       "   'prismatic.a.1',\n",
       "   'prismatic.u.2',\n",
       "   'incrassate.u.2',\n",
       "   'take_off.u.4'],\n",
       "  'hops': 0,\n",
       "  'distractor_hops': 0,\n",
       "  'chain': '',\n",
       "  'distractor_chain': '',\n",
       "  'other_distractors': [],\n",
       "  'word': 'prismatic',\n",
       "  'sense_choices': 2},\n",
       " 'id': '4'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_raw[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 20,\n",
       " 'premise': 'a <mask> person',\n",
       " 'hypothesis': 'the best context for <mask> here is Having peculiar views; fanciful; visionary; but not In a dependent manner..',\n",
       " 'gold_label': 'entailed'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "train_data = []\n",
    "\n",
    "for id, question in enumerate(train_data_raw):\n",
    "  premise = question['question']['stem'].split(\"'\")[1]\n",
    "  term = question['question']['stem'].split(\"'\")[3]\n",
    "  premise = premise.replace(term, '<mask>')\n",
    "  choices = question['question']['choices']\n",
    "  answer = choices[int(question['answerKey'])]['text']\n",
    "  choice_ids = [i for i in range(len(choices))]\n",
    "  choice_ids.remove(int(question['answerKey']))\n",
    "  wrong = choices[random.choice(choice_ids)]['text']\n",
    "\n",
    "  if id % 2 == 0:\n",
    "    hypothesis = f\"the best context for <mask> here is {answer}; but not {wrong}.\"\n",
    "    label = \"entailed\"\n",
    "  else:\n",
    "    hypothesis = f\"the best context for <mask> here is {wrong}; but not {answer}.\"\n",
    "    label = \"not-entailed\"\n",
    "  example = {\n",
    "    \"id\": id,\n",
    "    \"premise\": premise,\n",
    "    \"hypothesis\": hypothesis,\n",
    "    \"gold_label\": label\n",
    "  }\n",
    "  train_data.append(example)\n",
    "\n",
    "train_data[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4888"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data = train_data + wrong_predictions\n",
    "len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_good = get_k_shot_data_multi(good_predictions, k=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data += val_data_good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = []\n",
    "\n",
    "for id, question in enumerate(val_data_raw):\n",
    "  premise = question['question']['stem'].split(\"'\")[1]\n",
    "  term = question['question']['stem'].split(\"'\")[3]\n",
    "  #premise = premise.replace(term, 'something')\n",
    "  choices = question['question']['choices']\n",
    "  answer = choices[int(question['answerKey'])]['text']\n",
    "  hypothesis = f\"a specific type of {term} is {choice['text']} .\"\n",
    "  example = {\n",
    "    \"id\": id,\n",
    "    \"premise\": premise,\n",
    "    \"hypothesis\": hypothesis,\n",
    "    \"gold_label\": \"entailed\"\n",
    "  }\n",
    "  val_data.append(example)\n",
    "  for j, choice in enumerate(choices):\n",
    "    if j != int(question['answerKey']):\n",
    "      counter_example = {\n",
    "        \"id\": id,\n",
    "        \"premise\": premise,\n",
    "        \"hypothesis\": f\"a specific type of {term} is {choice['text']} .\",\n",
    "        \"gold_label\": \"not-entailed\"\n",
    "      }\n",
    "      val_data.append(counter_example)\n",
    "\n",
    "val_data[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_data = get_k_shot_data(train_data, k_p=10000, k_n=10000)\n",
    "new_val_data = get_k_shot_data(val_data, k_p=4250, k_n=4250)\n",
    "\n",
    "count_labels(new_train_data)\n",
    "count_labels(new_val_data)\n",
    "\n",
    "train_data = new_train_data\n",
    "val_data = new_val_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transitive Convertor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_table(\"./curriculum/transitive/train.tsv\")\n",
    "val_df = pd.read_table(\"./curriculum/transitive/val.tsv\")\n",
    "\n",
    "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "val_df = val_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "train_data_trans = []\n",
    "val_data_trans = []\n",
    "\n",
    "train_count = {}\n",
    "val_count = {}\n",
    "\n",
    "for i, row in train_df.iterrows():\n",
    "  premise = row['sentence1']\n",
    "  hypothesis = row['sentence2']\n",
    "  if row['gold_label'] == \"neutral\":\n",
    "    gold_label = \"not-entailed\"\n",
    "  else:\n",
    "    gold_label = \"entailed\"\n",
    "  example = {\n",
    "    \"id\": i,\n",
    "    \"premise\": premise,\n",
    "    \"hypothesis\": hypothesis,\n",
    "    \"gold_label\": gold_label\n",
    "  }\n",
    "\n",
    "  if not row['genre'] in train_count:\n",
    "    train_count[row['genre']] = [example]\n",
    "  elif len(train_count[row['genre']]) < 2000:\n",
    "    train_count[row['genre']].append(example)\n",
    "\n",
    "for i, row in train_df.iterrows():\n",
    "  premise = row['sentence1']\n",
    "  hypothesis = row['sentence2']\n",
    "  if row['gold_label'] == \"neutral\":\n",
    "    gold_label = \"not-entailed\"\n",
    "  else:\n",
    "    gold_label = \"entailed\"\n",
    "  example = {\n",
    "    \"id\": i,\n",
    "    \"premise\": premise,\n",
    "    \"hypothesis\": hypothesis,\n",
    "    \"gold_label\": gold_label\n",
    "  }\n",
    "  if not row['genre'] in val_count:\n",
    "    val_count[row['genre']] = [example]\n",
    "  elif len(val_count[row['genre']]) < 2000:\n",
    "    val_count[row['genre']].append(example)\n",
    "\n",
    "for key in train_count:\n",
    "  train_data_trans += train_count[key]\n",
    "\n",
    "for key in val_count:\n",
    "  val_data_trans += val_count[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_labels(train_data_trans)\n",
    "count_labels(val_data_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jiant.utils.python.io as py_io\n",
    "\n",
    "train_data_mega = py_io.read_jsonl(\"/content/tasks/curriculum/megaveridicality/train.jsonl\", mode=\"r\")\n",
    "train_data_fact = py_io.read_jsonl(\"/content/tasks/curriculum/factuality/train.jsonl\", mode=\"r\")\n",
    "\n",
    "val_data_mega = py_io.read_jsonl(\"/content/tasks/curriculum/megaveridicality/val.jsonl\", mode=\"r\")\n",
    "val_data_fact = py_io.read_jsonl(\"/content/tasks/curriculum/factuality/val.jsonl\", mode=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_labels(val_data_fact)\n",
    "count_labels(val_data_mega)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_labels(train_data_mega)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = get_k_shot_data(train_data_mega, k_p=3150, k_n=3150)\n",
    "train_data += train_data_trans\n",
    "train_data +=  get_k_shot_data(train_data_fact, k_p=1850, k_n=1850)\n",
    "val_data = get_k_shot_data(val_data_mega, k_p=394, k_n=394)\n",
    "val_data += get_k_shot_data(val_data_trans, k_p=3000, k_n=3000)\n",
    "val_data += get_k_shot_data(val_data_fact, k_p=1000, k_n=1000)\n",
    "\n",
    "count_labels(train_data)\n",
    "count_labels(val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Syllogism and SEM-Relation Convertor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "train_data_raw = [0] * 8\n",
    "\n",
    "for root, dirs, files in os.walk('./curriculum/syllogism/train'):\n",
    "    i = -1\n",
    "    for file in files:\n",
    "      if \"0-train\" in file:\n",
    "        i += 1\n",
    "      subset = py_io.read_jsonl(f\"./curriculum/syllogism/train/{file}\", encoding=\"utf8\")\n",
    "      if train_data_raw[i] == 0:\n",
    "        train_data_raw[i] = subset\n",
    "      else:\n",
    "        train_data_raw[i] += subset\n",
    "\n",
    "len(train_data_raw[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xmltodict\n",
    "\n",
    "train_text = {}\n",
    "\n",
    "with open('./curriculum/sem_relation/1.1.text.xml', 'r', encoding=\"utf8\") as file:\n",
    "  train_text = xmltodict.parse(''.join(file.readlines()))\n",
    "\n",
    "train_text.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogiQA Convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "answer_key = {\n",
    "  \"a\":4, \"b\":5, \"c\":6, \"d\":7\n",
    "}\n",
    "\n",
    "train_data = []\n",
    "\n",
    "with open('./curriculum/logicqa/train.txt', 'r', encoding=\"utf-8\") as file:\n",
    "  lines = file.readlines()\n",
    "  idx = 0\n",
    "  for i in range(0, len(lines), 8):\n",
    "    entailed = lines[i+answer_key[lines[i+1].replace('\\n', '')]]\n",
    "    seeds = [4,5,6,7]\n",
    "    seeds.remove(answer_key[lines[i+1].replace('\\n', '')])\n",
    "    neg_key = random.choice(seeds)\n",
    "    not_entailed = lines[i+neg_key]\n",
    "    example_p = {\n",
    "      \"idx\": idx,\n",
    "      \"premise\": lines[i+2].replace('\\n', ''),\n",
    "      \"hypothesis\": entailed.replace(\"A.\", \"\").replace(\"B.\", \"\").replace(\"C.\", \"\").replace(\"D.\", \"\").replace('\\n', ''),\n",
    "      \"gold_label\": \"entailed\",\n",
    "    }\n",
    "    idx += 1\n",
    "    example_n = {\n",
    "      \"idx\": idx,\n",
    "      \"premise\": lines[i+2].replace('\\n', ''),\n",
    "      \"hypothesis\": not_entailed.replace(\"A.\", \"\").replace(\"B.\", \"\").replace(\"C.\", \"\").replace(\"D.\", \"\").replace('\\n', ''),\n",
    "      \"gold_label\": \"not-entailed\",\n",
    "    }\n",
    "    idx += 1\n",
    "    train_data.append(example_p)\n",
    "    train_data.append(example_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = []\n",
    "\n",
    "with open('./curriculum/logicqa/dev.txt', 'r', encoding=\"utf-8\") as file:\n",
    "  lines = file.readlines()\n",
    "  idx = 0\n",
    "  for i in range(0, len(lines), 8):\n",
    "    entailed = lines[i+answer_key[lines[i+1].replace('\\n', '')]]\n",
    "    seeds = [4,5,6,7]\n",
    "    seeds.remove(answer_key[lines[i+1].replace('\\n', '')])\n",
    "    neg_key = random.choice(seeds)\n",
    "    not_entailed = lines[i+neg_key]\n",
    "    example_p = {\n",
    "      \"idx\": idx,\n",
    "      \"premise\": lines[i+2].replace('\\n', ''),\n",
    "      \"hypothesis\": entailed.replace(\"A.\", \"\").replace(\"B.\", \"\").replace(\"C.\", \"\").replace(\"D.\", \"\").replace('\\n', ''),\n",
    "      \"gold_label\": \"entailed\",\n",
    "    }\n",
    "    idx += 1\n",
    "    example_n = {\n",
    "      \"idx\": idx,\n",
    "      \"premise\": lines[i+2].replace('\\n', ''),\n",
    "      \"hypothesis\": not_entailed.replace(\"A.\", \"\").replace(\"B.\", \"\").replace(\"C.\", \"\").replace(\"D.\", \"\").replace('\\n', ''),\n",
    "      \"gold_label\": \"not-entailed\",\n",
    "    }\n",
    "    idx += 1\n",
    "    val_data.append(example_p)\n",
    "    val_data.append(example_n)\n",
    "\n",
    "with open('./curriculum/logicqa/test.txt', 'r', encoding=\"utf-8\") as file:\n",
    "  lines = file.readlines()\n",
    "  idx = 0\n",
    "  for i in range(0, len(lines), 8):\n",
    "    entailed = lines[i+answer_key[lines[i+1].replace('\\n', '')]]\n",
    "    seeds = [4,5,6,7]\n",
    "    seeds.remove(answer_key[lines[i+1].replace('\\n', '')])\n",
    "    neg_key = random.choice(seeds)\n",
    "    not_entailed = lines[i+neg_key]\n",
    "    example_p = {\n",
    "      \"idx\": idx,\n",
    "      \"premise\": lines[i+2].replace('\\n', ''),\n",
    "      \"hypothesis\": entailed.replace(\"A.\", \"\").replace(\"B.\", \"\").replace(\"C.\", \"\").replace(\"D.\", \"\").replace('\\n', ''),\n",
    "      \"gold_label\": \"entailed\",\n",
    "    }\n",
    "    idx += 1\n",
    "    example_n = {\n",
    "      \"idx\": idx,\n",
    "      \"premise\": lines[i+2].replace('\\n', ''),\n",
    "      \"hypothesis\": not_entailed.replace(\"A.\", \"\").replace(\"B.\", \"\").replace(\"C.\", \"\").replace(\"D.\", \"\").replace('\\n', ''),\n",
    "      \"gold_label\": \"not-entailed\",\n",
    "    }\n",
    "    idx += 1\n",
    "    val_data.append(example_p)\n",
    "    val_data.append(example_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPRL Convertor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "val_data = []\n",
    "\n",
    "with open('./curriculum/sprl_data.txt', 'r', encoding=\"utf-8\") as file:\n",
    "  lines = file.readlines()\n",
    "  idx = 0\n",
    "  for i in range(0, len(lines)-7, 7):\n",
    "    label = lines[i+4].split(':')\n",
    "    if not \"entailed\" in lines[i+4]:\n",
    "      print(i)\n",
    "    example = {\n",
    "      \"idx\": idx,\n",
    "      \"premise\": lines[i+2].replace('\\n', '').replace(\"text: \", \"\"),\n",
    "      \"hypothesis\": lines[i+3].replace('\\n', '').replace(\"hypothesis: \", \"\"),\n",
    "      \"gold_label\": label[1].replace(\"\\n\", \"\").strip(),\n",
    "    }\n",
    "    idx += 1\n",
    "    if \"train\" in lines[i+5]:\n",
    "      train_data.append(example)\n",
    "    elif \"test\" in lines[i+5]:\n",
    "      val_data.append(example)\n",
    "    elif \"dev\" in lines[i+5]:\n",
    "      val_data.append(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jiant.utils.python.io as py_io\n",
    "\n",
    "lexical_syntactic_tasks = [\n",
    "    \"transitive\",\n",
    "    \"hypernymy\",\n",
    "    \"hyponymy\",\n",
    "    \"ner\",\n",
    "    \"verbnet\",\n",
    "    \"verbcorner\",\n",
    "    \"syntactic_alternation\",\n",
    "    \"mrpc\",\n",
    "]\n",
    "\n",
    "logical_tasks = [\n",
    "    \"boolean\",\n",
    "    \"comparative\",\n",
    "    \"conditional\",\n",
    "    \"counting\",\n",
    "    \"negation\",\n",
    "    \"quantifier\",\n",
    "    \"monotonicity_infer\",\n",
    "    \"syllogism\"\n",
    "]\n",
    "\n",
    "semantic_tasks = [\n",
    "    \"sentiment\",\n",
    "    \"kg_relations\",\n",
    "    \"puns\",\n",
    "    \"coreference\",\n",
    "    \"context_align\",\n",
    "    \"sprl\",\n",
    "    \"entailment_tree\"\n",
    "]\n",
    "\n",
    "complex_tasks = [\n",
    "    \"socialqa\",\n",
    "    \"physicalqa\",\n",
    "    \"atomic\",\n",
    "    \"social_chem\",\n",
    "    \"logiqa\",\n",
    "    \"cosmoqa\",\n",
    "    \"ester\"\n",
    "]\n",
    "\n",
    "ANLI = ['adversarial_nli_r1',\n",
    "        'adversarial_nli_r2',\n",
    "        'adversarial_nli_r3']\n",
    "\n",
    "CURRICULUM = lexical_syntactic_tasks + logical_tasks \\\n",
    "    + semantic_tasks + complex_tasks + ANLI\n",
    "\n",
    "\n",
    "os.makedirs(\"./configs/\", exist_ok=True)\n",
    "\"\"\"os.makedirs(f\"/content/tasks/curriculum/{task_name}\", exist_ok=True)\n",
    "py_io.write_jsonl(\n",
    "    data=train_data,\n",
    "    path=f\"/content/tasks/curriculum/{task_name}/train.jsonl\",\n",
    ")\n",
    "py_io.write_jsonl(\n",
    "    data=val_data,\n",
    "    path=f\"/content/tasks/curriculum/{task_name}/val.jsonl\",\n",
    ")\"\"\"\n",
    "\n",
    "for task_name in CURRICULUM:\n",
    "  py_io.write_json({\n",
    "    \"task\": f\"{task_name}\",\n",
    "    \"paths\": {\n",
    "      \"train\": f\"../curriculum/{task_name}/train.jsonl\",\n",
    "      \"val\": f\"../curriculum/{task_name}/val.jsonl\",\n",
    "    },\n",
    "    \"name\": f\"{task_name}\"\n",
    "  }, f\"./configs/{task_name}_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for example in train_data_raw:\n",
    "  label = \"entailment\"\n",
    "  if example['label'] == \"neutral\":\n",
    "    label = example['label']\n",
    "  val = {\n",
    "    'sentence1': example['premise'],\n",
    "    'sentence2': example['hypothesis'],\n",
    "    'gold_label': label\n",
    "  }\n",
    "  train_data.append(val)\n",
    "\n",
    "val_data = []\n",
    "for example in val_data_raw:\n",
    "  label = \"entailment\"\n",
    "  if example['label'] == \"neutral\":\n",
    "    label = example['label']\n",
    "  val = {\n",
    "    'sentence1': example['premise'],\n",
    "    'sentence2': example['hypothesis'],\n",
    "    'gold_label': label\n",
    "  }\n",
    "  val_data.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_TOKEN = \"<S>\"\n",
    "SPAN1_TOKEN = \"<SP1>\"\n",
    "SPAN2_TOKEN = \"<SP2>\"\n",
    "MASK_TOKEN = \"[MASK]\"\n",
    "\n",
    "def generate_prompt(example, prompts):\n",
    "  template = \"<S> Based on the given context , <SP1> ? [MASK] <SP2>\"\n",
    "  for target in example['targets']:\n",
    "    prompt = template.replace(CONTEXT_TOKEN, example['text'])\n",
    "    sequence = example['text'].split(\" \")\n",
    "    span1_idx = target['span1']\n",
    "    span2_idx = target['span2']\n",
    "    label = target['label']\n",
    "    span1 = sequence[int(span1_idx[0]):int(span1_idx[1])]\n",
    "    span2 = sequence[int(span2_idx[0]):int(span2_idx[1])]\n",
    "    prompt = prompt.replace(SPAN1_TOKEN, \" \".join(span1))\n",
    "    prompt = prompt.replace(SPAN2_TOKEN, \" \".join(span2))\n",
    "    mask_idx = prompt.split(\" \").index(MASK_TOKEN)\n",
    "    new_example = {\n",
    "      'text': prompt,\n",
    "      'masked_spans': [[mask_idx, mask_idx+1]],\n",
    "      'target': label\n",
    "    }\n",
    "    prompts.append(new_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_train = []\n",
    "prompts_val = []\n",
    "\n",
    "for data in train_data:\n",
    "  generate_prompt(data, prompts_train)\n",
    "for data_val in train_data:\n",
    "  generate_prompt(data_val, prompts_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompts_train[0])\n",
    "prompts_train[0]['text'].split(\" \"[])[49:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_raw = py_io.read_jsonl(\"/content/tasks/curriculum/ner_complete/train.jsonl\")\n",
    "val_data_raw = py_io.read_jsonl(\"/content/tasks/curriculum/ner_complete/val.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = get_k_shot_data(train_data_raw, k_p=10000, k_n=10000)\n",
    "val_data = get_k_shot_data(val_data_raw, k_p=4250, k_n=4250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Uvt8Zi86yHHa"
   },
   "outputs": [],
   "source": [
    "task_name = \"entailment_tree\"\n",
    "\n",
    "os.makedirs(\"/content/tasks/configs/\", exist_ok=True)\n",
    "os.makedirs(f\"/content/tasks/curriculum/{task_name}\", exist_ok=True)\n",
    "py_io.write_jsonl(\n",
    "    data=train_data,\n",
    "    path=f\"/content/tasks/curriculum/{task_name}/train.jsonl\",\n",
    ")\n",
    "py_io.write_jsonl(\n",
    "    data=val_data,\n",
    "    path=f\"/content/tasks/curriculum/{task_name}/val.jsonl\",\n",
    ")\n",
    "py_io.write_json({\n",
    "  \"task\": f\"{task_name}\",\n",
    "  \"paths\": {\n",
    "    \"train\": f\"/content/tasks/curriculum/{task_name}/train.jsonl\",\n",
    "    \"val\": f\"/content/tasks/curriculum/{task_name}/val.jsonl\",\n",
    "  },\n",
    "  \"name\": f\"{task_name}\"\n",
    "}, f\"/content/tasks/configs/{task_name}_config.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HPZHyLOlVp07"
   },
   "source": [
    "#### Download model\n",
    "\n",
    "Next, we will download a `roberta-base` model. This also includes the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269,
     "referenced_widgets": [
      "0ad0c4ef8cc64749b6bd2ccb2ba41563",
      "d0fb730b54044b8583fdf3ee0476cb52",
      "4d260f0aaa1d4e1498c8895bf3c418b2",
      "bf55400872a34cbcb3527870b2191c8f",
      "1a0f2e4658744f6abfbfd1a3c8ae0d81",
      "448fafdecf8c46588f95cc4383942e59",
      "a233d58461ad4ab98181153139d76571",
      "660a5872700947a4b20a7eb2d3eb80ac",
      "273d939ae19a47ae976c3a7afe9403b8",
      "e99430b62eb141798053b07ea119a1ad",
      "cb0bcb188961445b96feec69f0477eea",
      "40a3f4a2ac2240469a787a06e4a6a361",
      "ca9f84de217a46acaf4906bad6851c7b",
      "a27515c619da49e187318ae10c3afb46",
      "e8f2532f90134a07b1e2727a7b83471c",
      "fe65d5ec01ea4f95a19808d8894d1e2c",
      "cba1747a59364cab89af52f64d7d2be4",
      "04c29dbb9a154153a86eb7e35d7a374e",
      "78f0337d61ff43b3ba17719c4f9e05fa",
      "49fcb769f4e34e2d870b8aff33267cb9",
      "f9770a94eb4044dd90fe74991c56d1c5",
      "afe39f56bc4c40f8967a6e5b358d9476",
      "e1c00cf74ea94eb9b61afd46bb042025",
      "0aee9253d3a14716a0a67dfda31f7a0f",
      "c795cd64b082451f9876de86ea6353ea",
      "089916ffd2064364acae7fbb0f77113e",
      "74b9301d8a3a4bd7a6fb4c15cd6f26a0",
      "aa6beffff7f34d59a6552f45725f1c77",
      "908f97b966be42d0a995df0dbb3ebd2b",
      "a4067515d3e34605a03e21fe7e4b1957",
      "9783cdbe47fd4177ba89e447bf843a25",
      "4fb3f4ea5d9c4705b3e9b0dd0408fe07"
     ]
    },
    "id": "K06qUGjkKWa7",
    "outputId": "c21bdffa-0ff3-49f3-e734-af5530ab4711"
   },
   "outputs": [],
   "source": [
    "import jiant.proj.main.export_model as export_model\n",
    "\n",
    "export_model.export_model(\n",
    "    hf_pretrained_model_name_or_path=\"ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli\",\n",
    "    output_base_path=\"./models/anli-mix-roberta\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dV-T-8r1V0wf"
   },
   "source": [
    "#### Tokenize and cache\n",
    "\n",
    "With the model and data ready, we can now tokenize and cache the inputs features for our task. This converts the input examples to tokenized features ready to be consumed by the model, and saved them to disk in chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168,
     "referenced_widgets": [
      "558652d65c9c42e5b2487711ea8c5183",
      "b59db489de7a410fb16ac4c64554c2db",
      "648bd87cbe344ce786e78d902456be01",
      "763685078bfa425a84652935a1d49965",
      "5cada33c5612410482ab58422f866621",
      "635bed807450413797ec7d1c8a16444d",
      "9878a78abe8e41c585f63ed1e77309ea",
      "2b0ee8fa0e614926b8ea2befa8d93893",
      "6bfcf6f5ebc144e88f55e1501c398ab3",
      "0fe088ff545b4642993a0395bc0351af",
      "6644d495d3ab4198962cc3e4fd130fe0",
      "95e0eeb66af842fc9a5ea7072e665045",
      "13039f3a86204fdea19dd335aaa66519",
      "effe903b59b24573b1c3e406b986dfac",
      "b6aeddb44c3147e2ab912d84759bc139",
      "1b51de8cdcbd4c01af4de5865e9c575d"
     ]
    },
    "id": "22bNWQajO4zm",
    "outputId": "a8cf3ed5-c86f-42aa-9a20-c9e97dc51998",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import jiant.proj.main.tokenize_and_cache as tokenize_and_cache\n",
    "\n",
    "bert1 = \"bert-base-uncased\"\n",
    "bert2 = \"bert-large-uncased\"\n",
    "roberta1 = \"roberta-base\"\n",
    "roberta2 = \"roberta-large\"\n",
    "deberta = \"microsoft/deberta-base\"\n",
    "\n",
    "task_name = \"factuality\"\n",
    "model_name = bert1\n",
    "\n",
    "tokenize_and_cache.main(tokenize_and_cache.RunConfiguration(\n",
    "    task_config_path=f\"/content/tasks/configs/{task_name}_config.json\",\n",
    "    hf_pretrained_model_name_or_path=model_name,\n",
    "    output_dir=f\"./cache/{model_name}/{task_name}\",\n",
    "    phases=[\"train\", \"val\"],\n",
    "))\n",
    "\n",
    "model_name = roberta1\n",
    "\n",
    "tokenize_and_cache.main(tokenize_and_cache.RunConfiguration(\n",
    "    task_config_path=f\"/content/tasks/configs/{task_name}_config.json\",\n",
    "    hf_pretrained_model_name_or_path=model_name,\n",
    "    output_dir=f\"./cache/{model_name}/{task_name}\",\n",
    "    phases=[\"train\", \"val\"],\n",
    "))\n",
    "\n",
    "model_name = deberta\n",
    "\n",
    "tokenize_and_cache.main(tokenize_and_cache.RunConfiguration(\n",
    "    task_config_path=f\"/content/tasks/configs/{task_name}_config.json\",\n",
    "    hf_pretrained_model_name_or_path=model_name,\n",
    "    output_dir=f\"./cache/{model_name}/{task_name}\",\n",
    "    phases=[\"train\", \"val\"],\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model = torch.load(\"./models/microsoft/deberta-base-mnli/model/model.p\")\n",
    "model.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3MBuH19IWOr0"
   },
   "source": [
    "#### Writing a run config\n",
    "\n",
    "Here we are going to write what we call a `jiant_task_container_config`. This configuration file basically defines a lot of the subtleties of our training pipeline, such as what tasks we will train on, do evaluation on, batch size for each task. The new version of `jiant` leans heavily toward explicitly specifying everything, for the purpose of inspectability and leaving minimal surprises for the user, even as the cost of being more verbose.\n",
    "\n",
    "We use a helper \"Configurator\" to write out a `jiant_task_container_config`, since most of our setup is pretty standard. \n",
    "\n",
    "**Depending on what GPU your Colab session is assigned to, you may need to lower the train batch size.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_configuration(task_name, model_name):\n",
    "    jiant_run_config = configurator.SimpleAPIMultiTaskConfigurator(\n",
    "        task_config_base_path=\"/content/tasks/configs/\",\n",
    "        task_cache_base_path=f\"./cache/{model_name}/\",\n",
    "        train_task_name_list=[task_name],\n",
    "        val_task_name_list=[task_name],\n",
    "        train_batch_size=8,\n",
    "        eval_batch_size=16,\n",
    "        epochs=5,\n",
    "        num_gpus=1,\n",
    "    ).create_config()\n",
    "\n",
    "    os.makedirs(\"./run_configs/\", exist_ok=True)\n",
    "    py_io.write_json(jiant_run_config,\n",
    "                     f\"./run_configs/{task_name}_run_config.json\")\n",
    "    display.show_json(jiant_run_config)\n",
    "\n",
    "def train(task_name, model_name):\n",
    "    run_args = main_runscript.RunConfiguration(\n",
    "        jiant_task_container_config_path=f\"./run_configs/{task_name}_run_config.json\",\n",
    "        output_dir=f\"./runs/{task_name}\",\n",
    "        hf_pretrained_model_name_or_path=model_name,\n",
    "        model_path=f\"./models/{model_name}/model/model.p\",\n",
    "        model_config_path=f\"./models/{model_name}/model/config.json\",\n",
    "        learning_rate=1e-5,\n",
    "        eval_every_steps=500,\n",
    "        do_train=True,\n",
    "        do_val=True,\n",
    "        do_save=True,\n",
    "        write_val_preds=True,\n",
    "        freeze_encoder=True,\n",
    "        force_overwrite=True,\n",
    "        no_cuda=False\n",
    "    )\n",
    "    main_runscript.run_loop(run_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForMaskedLM\n",
    "import torch\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaForMaskedLM.from_pretrained('roberta-base')\n",
    "\n",
    "inputs = tokenizer(\"There are <mask> people walking, a man, a woman, and two childern.\", return_tensors=\"pt\")\n",
    "labels = tokenizer(\"There are 4 people walking, a man, a woman, and two childern.\", return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "outputs = model(**inputs, labels=labels)\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tokenizer.encode(\"A person who diagnose illnesses works at the hospital. The hospital is where a doctor works. Based on the context, the word illnesses is a <mask>\", return_tensors=\"pt\")\n",
    "mask_token_index = torch.where(input == tokenizer.mask_token_id)[1]\n",
    "token_logits = model(input).logits\n",
    "mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "top_3_tokens = torch.topk(mask_token_logits, 3, dim=1).indices[0].tolist()\n",
    "for token in top_3_tokens:\n",
    "  print(tokenizer.decode([token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctor_def = [\"helps a sick person\", \"treats a patient\", \"cures a person's disease\",\n",
    "              \"diagnoses illnesses\", \"prescribes medicine\"]\n",
    "lawyer_def = ['represents you in court', 'objects in court', 'questions a witness',\n",
    "              'rests the case', 'settles a law suit']\n",
    "teacher_def = ['teaches students', 'assigns homework', 'works in a school',\n",
    "               'dares you to learn', 'explains a fact']\n",
    "engineer_def = ['invents and designs structures', 'analyzes, builds, and tests complex systems'\n",
    "                'forms the link between scientific discoveries to human and business needs',\n",
    "                'develops new technological solutions',\n",
    "                'applies engineering analysis in testing, production, or maintenance']\n",
    "entrepreneur_def = ['creates a new business', 'takes on the risks of creating a startup',\n",
    "                    'organizes and operates a business', 'needs to ensure funding',\n",
    "                    'brings good new ideas to market']\n",
    "firefighter_def = ['is resbonsible for fire and rescure',\n",
    "                   'rushes to a burning building', 'pulls a hoes',\n",
    "                   'rescues people from dangerous situations',\n",
    "                   'carries out a ladder slider', 'extinguish fires']\n",
    "sailor_def = ['captains a ship', 'sails a ship', 'ties a knot',\n",
    "              'sounds the depth of the sea', 'boards a boat']\n",
    "actor_def = ['stars in a movie or TV show', 'acts scene in a play',\n",
    "             'puts on a costume', 'appears at the theater', 'pictures a scene']\n",
    "architect_def = ['positions walls and plumbing with exactness', 'completes a floor plan',\n",
    "                 'plans, designs and oversees the construction of buildings',\n",
    "                 'pictures a structural design',\n",
    "                 'illustrates and generates bulding design proposals']\n",
    "nurse_def = ['cares for a patient', 'pages the doctor',\n",
    "             'checks vital signs', 'hands the instrument to the doctor', 'takes a pulse']\n",
    "journalist_def = ['reads a press release', 'reports news', 'covers a story',\n",
    "                  'interviews strangers with a microphone', 'notes a discrepancy in the facts']\n",
    "policeman_def = [\"is in a police force\", 'prevents and detects crimes',\n",
    "                 'protects and assists the general public', 'arrests criminals', 'investigates a crime']\n",
    "writer_def = ['write a novel', 'words things for impact', 'writes poems',\n",
    "              'words a phrase carefully', 'tells a story in a book']\n",
    "programmer_def = ['step through a computer program', 'writes a software',\n",
    "                  'sets up a website', 'understands programming language', 'fix a software bug']\n",
    "carpenter_def = ['builds a house', 'hammers a nail', 'plains a door',\n",
    "                 'nail furniture together', 'build roof, cabninets, and shelves']\n",
    "baker_def = ['rolls dough', 'makes a cake', 'bake a wedding cake', 'flower a table',\n",
    "             'coat a cake with lemon-flavored frosting']\n",
    "chef_def = ['prepares food', 'works at restaurants and hotels', 'cooks a gourmet meal',\n",
    "            'cooks very well', 'can bread chicken']\n",
    "accountant_def = ['is a practitioner of accounting',\n",
    "                  \"has the ability to certify an organization's financial statements\",\n",
    "                  'complete a tax return', 'audits books for different companies', 'cooks the books']\n",
    "farmer_def = ['farms the land', 'seeds the field', 'waters and gather the crops',\n",
    "              'normaly owns a barn', 'feeds many farm animals']\n",
    "scientist_def = ['conducts scientific research to advance knowledge',\n",
    "                 'has an advanced degrees in an area of science',\n",
    "                 'exhibits a strong curiosity about reality',\n",
    "                 'applies scientific knowledge for the benefit of people',\n",
    "                 'performs experiments to test hypotheses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computer_def = []\n",
    "pencil_def = []\n",
    "watch = []\n",
    "phone = []\n",
    "baterry = []\n",
    "car = []\n",
    "drills = []\n",
    "dictionary_def = ['A tool that people use to look up word definition']\n",
    "soap = []\n",
    "lamp = []\n",
    "mirror = []\n",
    "cooker = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airport_def = ['is where people get on airplanes',\n",
    "               'has an air traffic control tower',\n",
    "               'is used for airplane landing and taking off',\n",
    "               '',\n",
    "               '']\n",
    "hotel_def = ['is a place to stay when people travel',\n",
    "             'is where people can book a room',\n",
    "             'is used for a bed away from home',\n",
    "             'is an establishment providing accommodations for travelers',\n",
    "             'can provide paid lodging on a short-term basis']\n",
    "bank_def = ['is a financial institution that accepts deposits from the public',\n",
    "            'can create a demand deposit',\n",
    "            'plays an important role in financial stability and the economy of a country',\n",
    "            'is a subject to minimum capital requirements',\n",
    "            'is a place where people can apply for credit cards']\n",
    "hospital_def = ['is used for healing sick people',\n",
    "                'is a place to have surgery',\n",
    "                'is for treating seriously injured people',\n",
    "                'is a workplace for doctors and nurses',\n",
    "                'is able to handle medical emergencies']\n",
    "school_def = ['is a place for learning and teaching the students',\n",
    "              'is where people can get an education',\n",
    "              'provides learning spaces and learning environments',\n",
    "              'is where teachers work',\n",
    "              'typically has classrooms, a library, and a cafeteria']\n",
    "church_def = ['is where people pray to God']\n",
    "court_def = []\n",
    "cinema_def = []\n",
    "gym_def = []\n",
    "farm_def = []\n",
    "gallery_def = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mountain_def = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tokenizer.encode(\"A tool that people use to look up word definition is a <mask>\", return_tensors=\"pt\")\n",
    "mask_token_index = torch.where(input == tokenizer.mask_token_id)[1]\n",
    "token_logits = model(input).logits\n",
    "mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n",
    "for token in top_5_tokens:\n",
    "  print(tokenizer.decode([token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tokenizer.encode(\"Lava and volcanic ash comes from <mask>\", return_tensors=\"pt\")\n",
    "mask_token_index = torch.where(input == tokenizer.mask_token_id)[1]\n",
    "token_logits = model(input).logits\n",
    "mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n",
    "for token in top_5_tokens:\n",
    "  print(tokenizer.decode([token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tokenizer.encode(\"A professional who applies engineering analysis in testing, production, or maintenance is an <mask>\", return_tensors=\"pt\")\n",
    "mask_token_index = torch.where(input == tokenizer.mask_token_id)[1]\n",
    "token_logits = model(input).logits\n",
    "mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n",
    "for token in top_5_tokens:\n",
    "  print(tokenizer.decode([token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input = tokenizer.encode(\"A person who performs experiments to test hypotheses is a <mask>\", return_tensors=\"pt\")\n",
    "mask_token_index = torch.where(input == tokenizer.mask_token_id)[1]\n",
    "token_logits = model(input).logits\n",
    "mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n",
    "for token in top_5_tokens:\n",
    "  print(tokenizer.decode([token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tokenizer.encode(\"A man, a woman, and two children are walking on the beach. <mask> people are walking on the beach.\", return_tensors=\"pt\")\n",
    "mask_token_index = torch.where(input == tokenizer.mask_token_id)[1]\n",
    "token_logits = model(input).logits\n",
    "mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n",
    "for token in top_5_tokens:\n",
    "  print(tokenizer.decode([token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tokenizer.encode(\"Bert ate 2 <mask>, cake, ice cream, mochi, cotton candy, spinach, and cabbage.\", return_tensors=\"pt\")\n",
    "mask_token_index = torch.where(input == tokenizer.mask_token_id)[1]\n",
    "token_logits = model(input).logits\n",
    "mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n",
    "for token in top_5_tokens:\n",
    "  print(tokenizer.decode([token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "bart = torch.hub.load('pytorch/fairseq', 'bart.base')\n",
    "bart.cuda()\n",
    "bart.eval()\n",
    "bart.fill_mask(['The cat <mask> on the <mask>.'], topk=3, beam=10, match_source_len=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration, BartConfig\n",
    "\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "\n",
    "ARTICLE_TO_SUMMARIZE = \"While at Skidmore , Smith also designed an even taller mixed-use skyscraper , the Burj Dubai , now under construction in the United Arab Emirates .\"\n",
    "inputs = tokenizer([ARTICLE_TO_SUMMARIZE], max_length=1024, return_tensors='pt')\n",
    "\n",
    "# Generate Summary\n",
    "summary_ids = model.generate(inputs['input_ids'], num_beams=4, max_length=5, early_stopping=True)\n",
    "print([tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE_TO_SUMMARIZE = \"While at Skidmore , Smith also designed an even taller mixed-use skyscraper , the Burj Dubai , now under construction in the United Arab Emirates .\"\n",
    "inputs = tokenizer([ARTICLE_TO_SUMMARIZE], max_length=1024, return_tensors='pt')\n",
    "\n",
    "# Generate Summary\n",
    "summary_ids = model.generate(inputs['input_ids'], num_beams=5, max_length=10, early_stopping=True)\n",
    "print([tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4SXcuHFIYp6Y"
   },
   "source": [
    "Since we're training and evaluating on the same (duplicated) example, we should get perfect performance, but hopefully this notebook should be illustrative of the workflow for edge-probing tasks."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "jiant STILTs Example",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "183bbf6827d058c2a2fb0f4acdc0420849dda2b4380af0e437e38c64d798d8b7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "03fb6747a39646e3b7dda6f877ce19fe": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "04c29dbb9a154153a86eb7e35d7a374e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "089916ffd2064364acae7fbb0f77113e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ad0c4ef8cc64749b6bd2ccb2ba41563": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4d260f0aaa1d4e1498c8895bf3c418b2",
       "IPY_MODEL_bf55400872a34cbcb3527870b2191c8f"
      ],
      "layout": "IPY_MODEL_d0fb730b54044b8583fdf3ee0476cb52"
     }
    },
    "0aee9253d3a14716a0a67dfda31f7a0f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0bce1deff0d64bf7a96b6307efd4544e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "0ca001e7315c41359a48a37579ad7ac6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_17a6d908da41486995c53d7436990b8b",
      "placeholder": "​",
      "style": "IPY_MODEL_9ae696b3d7bd470787c4de833990a614",
      "value": " 374/375 [01:19&lt;00:00,  4.69it/s]"
     }
    },
    "0fe088ff545b4642993a0395bc0351af": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "13039f3a86204fdea19dd335aaa66519": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "17a6d908da41486995c53d7436990b8b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a0f2e4658744f6abfbfd1a3c8ae0d81": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "1b51de8cdcbd4c01af4de5865e9c575d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "273d939ae19a47ae976c3a7afe9403b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cb0bcb188961445b96feec69f0477eea",
       "IPY_MODEL_40a3f4a2ac2240469a787a06e4a6a361"
      ],
      "layout": "IPY_MODEL_e99430b62eb141798053b07ea119a1ad"
     }
    },
    "27e02234b1764aed9156f565ec454246": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b0ee8fa0e614926b8ea2befa8d93893": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3dbe5ad38b23422481c2e51acdc78b20": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40a3f4a2ac2240469a787a06e4a6a361": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe65d5ec01ea4f95a19808d8894d1e2c",
      "placeholder": "​",
      "style": "IPY_MODEL_e8f2532f90134a07b1e2727a7b83471c",
      "value": " 501M/501M [00:07&lt;00:00, 68.8MB/s]"
     }
    },
    "448fafdecf8c46588f95cc4383942e59": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "49fcb769f4e34e2d870b8aff33267cb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0aee9253d3a14716a0a67dfda31f7a0f",
      "placeholder": "​",
      "style": "IPY_MODEL_e1c00cf74ea94eb9b61afd46bb042025",
      "value": " 899k/899k [00:00&lt;00:00, 3.43MB/s]"
     }
    },
    "4b138e183eaf406a8fec6a2cc36f067a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b093c8725cf24d37861f2b38837f4bc4",
       "IPY_MODEL_62651b48746c4536a6814fefa89c91e6"
      ],
      "layout": "IPY_MODEL_ab66645a63274e67a823bed7702d5da2"
     }
    },
    "4d260f0aaa1d4e1498c8895bf3c418b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_448fafdecf8c46588f95cc4383942e59",
      "max": 481,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1a0f2e4658744f6abfbfd1a3c8ae0d81",
      "value": 481
     }
    },
    "4fb3f4ea5d9c4705b3e9b0dd0408fe07": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54e47f0d45d24009aa83fbb5d614e98a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "558652d65c9c42e5b2487711ea8c5183": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_648bd87cbe344ce786e78d902456be01",
       "IPY_MODEL_763685078bfa425a84652935a1d49965"
      ],
      "layout": "IPY_MODEL_b59db489de7a410fb16ac4c64554c2db"
     }
    },
    "5cada33c5612410482ab58422f866621": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "62651b48746c4536a6814fefa89c91e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27e02234b1764aed9156f565ec454246",
      "placeholder": "​",
      "style": "IPY_MODEL_9a83595e4bb74bc0948be54799248d16",
      "value": " 7/7 [00:01&lt;00:00,  4.72it/s]"
     }
    },
    "635bed807450413797ec7d1c8a16444d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "648bd87cbe344ce786e78d902456be01": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Tokenizing: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_635bed807450413797ec7d1c8a16444d",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5cada33c5612410482ab58422f866621",
      "value": 1000
     }
    },
    "660a5872700947a4b20a7eb2d3eb80ac": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6644d495d3ab4198962cc3e4fd130fe0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Tokenizing: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_effe903b59b24573b1c3e406b986dfac",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_13039f3a86204fdea19dd335aaa66519",
      "value": 100
     }
    },
    "69d9699a4d7147b5bf9ada54c4839488": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6bfcf6f5ebc144e88f55e1501c398ab3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6644d495d3ab4198962cc3e4fd130fe0",
       "IPY_MODEL_95e0eeb66af842fc9a5ea7072e665045"
      ],
      "layout": "IPY_MODEL_0fe088ff545b4642993a0395bc0351af"
     }
    },
    "70693f5e1708442d9377b03600d256c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bc31ec29b5f24d838401db71b345aeed",
      "placeholder": "​",
      "style": "IPY_MODEL_e1a1f7ae889e45ad9b825d752c74a38d",
      "value": " 7/7 [00:05&lt;00:00,  1.18it/s]"
     }
    },
    "74b9301d8a3a4bd7a6fb4c15cd6f26a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a4067515d3e34605a03e21fe7e4b1957",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_908f97b966be42d0a995df0dbb3ebd2b",
      "value": 456318
     }
    },
    "763685078bfa425a84652935a1d49965": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2b0ee8fa0e614926b8ea2befa8d93893",
      "placeholder": "​",
      "style": "IPY_MODEL_9878a78abe8e41c585f63ed1e77309ea",
      "value": " 1000/1000 [00:13&lt;00:00, 72.72it/s]"
     }
    },
    "78f0337d61ff43b3ba17719c4f9e05fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_afe39f56bc4c40f8967a6e5b358d9476",
      "max": 898823,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f9770a94eb4044dd90fe74991c56d1c5",
      "value": 898823
     }
    },
    "7b6147ac6008406c932bb5c5fbf9c8ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ff00a73e3d474420ab697edb5626da1b",
       "IPY_MODEL_70693f5e1708442d9377b03600d256c4"
      ],
      "layout": "IPY_MODEL_d41d7ce333404ac8b12feed2031f1cd2"
     }
    },
    "908f97b966be42d0a995df0dbb3ebd2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "91fac974c5eb4f19b7b0cf18e3521d82": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95e0eeb66af842fc9a5ea7072e665045": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b51de8cdcbd4c01af4de5865e9c575d",
      "placeholder": "​",
      "style": "IPY_MODEL_b6aeddb44c3147e2ab912d84759bc139",
      "value": " 100/100 [00:02&lt;00:00, 38.47it/s]"
     }
    },
    "968570f0cb0a45c7ab5ab76e00936ae3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9783cdbe47fd4177ba89e447bf843a25": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9878a78abe8e41c585f63ed1e77309ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9a83595e4bb74bc0948be54799248d16": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9ae696b3d7bd470787c4de833990a614": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a233d58461ad4ab98181153139d76571": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a27515c619da49e187318ae10c3afb46": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4067515d3e34605a03e21fe7e4b1957": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aa6beffff7f34d59a6552f45725f1c77": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4fb3f4ea5d9c4705b3e9b0dd0408fe07",
      "placeholder": "​",
      "style": "IPY_MODEL_9783cdbe47fd4177ba89e447bf843a25",
      "value": " 456k/456k [00:00&lt;00:00, 3.95MB/s]"
     }
    },
    "ab6394febb5b4d48b9d26d9846f0eb87": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Eval (semeval, Val): 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_91fac974c5eb4f19b7b0cf18e3521d82",
      "max": 7,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0bce1deff0d64bf7a96b6307efd4544e",
      "value": 7
     }
    },
    "ab66645a63274e67a823bed7702d5da2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad747e2552c5429484dcd3d19c366a96": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ab6394febb5b4d48b9d26d9846f0eb87",
       "IPY_MODEL_e34035b4fc8348f2ab108b9edc5d0322"
      ],
      "layout": "IPY_MODEL_54e47f0d45d24009aa83fbb5d614e98a"
     }
    },
    "afe39f56bc4c40f8967a6e5b358d9476": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b093c8725cf24d37861f2b38837f4bc4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Eval (semeval, Val): 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3dbe5ad38b23422481c2e51acdc78b20",
      "max": 7,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f5d8d08063f340f6b32bf7f2f0fd5821",
      "value": 7
     }
    },
    "b59db489de7a410fb16ac4c64554c2db": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6aeddb44c3147e2ab912d84759bc139": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bc31ec29b5f24d838401db71b345aeed": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf55400872a34cbcb3527870b2191c8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_660a5872700947a4b20a7eb2d3eb80ac",
      "placeholder": "​",
      "style": "IPY_MODEL_a233d58461ad4ab98181153139d76571",
      "value": " 481/481 [00:15&lt;00:00, 31.4B/s]"
     }
    },
    "c795cd64b082451f9876de86ea6353ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_74b9301d8a3a4bd7a6fb4c15cd6f26a0",
       "IPY_MODEL_aa6beffff7f34d59a6552f45725f1c77"
      ],
      "layout": "IPY_MODEL_089916ffd2064364acae7fbb0f77113e"
     }
    },
    "ca9f84de217a46acaf4906bad6851c7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "cb0bcb188961445b96feec69f0477eea": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a27515c619da49e187318ae10c3afb46",
      "max": 501200538,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ca9f84de217a46acaf4906bad6851c7b",
      "value": 501200538
     }
    },
    "cba1747a59364cab89af52f64d7d2be4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_78f0337d61ff43b3ba17719c4f9e05fa",
       "IPY_MODEL_49fcb769f4e34e2d870b8aff33267cb9"
      ],
      "layout": "IPY_MODEL_04c29dbb9a154153a86eb7e35d7a374e"
     }
    },
    "d0fb730b54044b8583fdf3ee0476cb52": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d41d7ce333404ac8b12feed2031f1cd2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4f840d6919047c795fbe22cc096ae39": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d5045b7014fa46518bb0378cf52fa76f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "db4132b9258440179d76382ed537257c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e1a1f7ae889e45ad9b825d752c74a38d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e1c00cf74ea94eb9b61afd46bb042025": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e23242c190344c098076d1fc8140e6f2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e34035b4fc8348f2ab108b9edc5d0322": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_03fb6747a39646e3b7dda6f877ce19fe",
      "placeholder": "​",
      "style": "IPY_MODEL_968570f0cb0a45c7ab5ab76e00936ae3",
      "value": " 7/7 [00:00&lt;00:00,  9.29it/s]"
     }
    },
    "e8e3b6cf03e04df99ac9799dbbe997cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "Training: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_db4132b9258440179d76382ed537257c",
      "max": 375,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d4f840d6919047c795fbe22cc096ae39",
      "value": 374
     }
    },
    "e8f2532f90134a07b1e2727a7b83471c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e99430b62eb141798053b07ea119a1ad": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "effe903b59b24573b1c3e406b986dfac": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f081100984b44e45a77fff620f998508": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e8e3b6cf03e04df99ac9799dbbe997cf",
       "IPY_MODEL_0ca001e7315c41359a48a37579ad7ac6"
      ],
      "layout": "IPY_MODEL_69d9699a4d7147b5bf9ada54c4839488"
     }
    },
    "f5d8d08063f340f6b32bf7f2f0fd5821": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f9770a94eb4044dd90fe74991c56d1c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "fe65d5ec01ea4f95a19808d8894d1e2c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff00a73e3d474420ab697edb5626da1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Eval (semeval, Val): 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e23242c190344c098076d1fc8140e6f2",
      "max": 7,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d5045b7014fa46518bb0378cf52fa76f",
      "value": 7
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
